# 论文信息
- 时间：2021
- 期刊：CVPR
- 网络名称：MAE 
- 意义：BERT的CV版
- 作者：Kaiming He∗,† , Xinlei Chen∗ , Saining Xie,  Yanghao Li,  Piotr Dollar,  Ross Girshick, ∗equal technical contribution, †project lead; Facebook AI Research (FAIR)
- 实验环境：128 TPU V-core
- 数据集：

[ppt](../ppt/MAE/MAE.pptx)

# 论文知识补充
- 做的模型很快叫`efficient`
- 做的模型很大叫`scalable`
- `Auto`在这篇论文中不是“自动”，而是“自”，如自回归 
# 一、解决的问题
- 在图片里加入噪声，然后让模型学习如何去噪
- Transformer和CNN的区别：
  1. 结构不一样，卷积难以加入掩码，无法区分边界
  2. 信息密度不一样，作者通过把高比率的块去掉，减少冗余
  3. 自编码器的解码器：CV还原较低层次的内容（像素），因此不能像NLP一样使用一个简单的全连接层，而是使用卷积或者其他层
# 二、做出的创新
1. 将BERT方法拓展到了CV中，通过MASK做完形填空
2. 将图片分割成多个小块，然后进行随机掩码，在进行打乱，再让模型进行复原
3. 编码器和解码器不对成，即看到的东西不一样
# 三、设计的模型

![MAE architecture](../pictures/MAE/MAE%20architecture.png)

- 图片切成小块
- 随机盖住一些块
- 把没改住的块拉成向量送入编码器
- 编码器结果中加入盖住的块，补充位置信息，送入解码器
- 让解码器把图片进行还原
- 通过这样的方式可以降低计算量
- 编码器就是ViT
- 解码器只有预训练的时候用

# 四、实验结果
- 遮盖的区域面积越小，还原的效果越好
## 1、模型的优势
- 只调最后一层，8个Transformer块更好
- 解码器的宽度512最好
- 编码器不用加入mask效果好，效率高
- 要做normalization
- 数据增强不敏感，随机大小剪裁最好
- 随机采样效果最好
- mask的百分率70%~80%最好
- epoch越多越好，1000轮也很不错
- fine-tuning 4-5层就很好了
## 2、有优势的原因

## 3、改进空间

# 五、结论

## 1、模型是否解决了目标问题

## 2、模型是否遗留了问题

## 3、模型是否引入了新的问题

# 六、代码

# 读者角度（挖掘文章中没有提到的）：
1. 总结文章发现问题的思路
- 一一引出BERT->CV可能出现的问题，一一解答后，引出了模型
- 类似工作还是要阐述，自己工作与他们的不同
2. 总结文章改进的思想
3. 总结文章还存在或者可以改进的问题
4. 提出对模型参数和细节的一些思考和讨论
