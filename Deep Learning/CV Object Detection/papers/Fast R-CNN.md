# 论文信息
- 时间：2015
- 期刊：ICCV
- 网络/算法名称：Fast R-CNN
- 意义：更快更准的R-CNN
- 作者：Ross Girshick（Microsoft Research）
- 实验环境：
- 数据集：PASCAL VOC 2012
- [返回上一层 README](../README.md)
# 一、解决的问题
1. 复杂性的产⽣是因为检测需要对物体进⾏准确定位，从⽽产⽣了两个主要挑战。⾸先，必须处理⼤量候选对象位置（通常称为“提案”）。其次，这些数据只能提供粗略的定位，必须对其进⾏细化才能实现精确定位。这些问题的解决⽅案通常会影响速度、准确性或简单性。
    - 在本⽂中，我们简化了最先进的基于 ConvNet 的⽬标检测器的训练过程[R-CNN](https://arxiv.org/pdf/1311.2524v5.pdf)和[SPPnet](https://www.semanticscholar.org/reader/cbb19236820a96038d000dc629225d36e0b6294a)。我们提出了⼀种单阶段训练算法，可以共同学习对⽬标提议进⾏分类并改进它们的空间位置。

    - 由此产⽣的⽅法可以训练⼀个⾮常深的检测⽹络（[VGG16](https://arxiv.org/pdf/1409.1556.pdf)），⽐[R-CNN](https://arxiv.org/pdf/1311.2524v5.pdf)快 9 倍，⽐ SPPnet 快 3 倍。在运⾏时，检测⽹络在 0.3 秒内处理图像（不包括对象提议时间）同时在 PASCAL VOC 2012 上实现最⾼准确度，mAP 为 66%（R-CNN 为 62%）.

2. R-CNN 和 SPPnet
- 基于区域的卷积⽹络⽅法 (R CNN) 通过使⽤深度卷积⽹络对⽬标提议进⾏分类，实现了出⾊的⽬标检测精度。然⽽，R-CNN 有明显的缺点：

    1. 训练是⼀个多阶段流⽔线。 R-CNN ⾸先使⽤对数损失对对象建议的 ConvNet 进⾏微调。然后，它使 SVM 适合 ConvNet 特征。这些 SVM 充当对象检测器，取代通过微调学习的 softmax 分类器。在第三个训练阶段，边界框回归器被学习。

    2. 培训在空间和时间上是昂贵的。对于 SVM 和边界框回归器训练，从每个图像中的每个对象建议中提取特征并将其写⼊磁盘。对于⾮常深的⽹络，例如 VGG16，对于 VOC07 trainval 集的 5k 图像，此过程需要 2.5 个 GPU ⽇。这些功能需要数百 GB 的存储空间。

    3. 物体检测速度慢。在测试时，从每个测试图像中的每个对象提议中提取特征。使⽤ VGG16 进⾏检测需要 47 秒/图像（在 GPU 上）。

- R-CNN 很慢，因为它对每个对象提案执⾏ ConvNet 前向传递，⽽不共享计算。空间⾦字塔池⽹络 [SPPnets](https://www.semanticscholar.org/reader/cbb19236820a96038d000dc629225d36e0b6294a) 被提议通过共享计算来加速 R-CNN。 SPPnet ⽅法计算整个输⼊图像的卷积特征图，然后使⽤从共享特征图中提取的特征向量对每个对象提议进⾏分类。通过将提议内的特征图部分最⼤池化为固定⼤⼩的输出（例如，6×6），为提议提取特征。多个输出⼤⼩被合并，然后像空间⾦字塔合并[Beyond bags of features: spatial pyramid matching for recognizing natural scene categories](https://hal.inria.fr/file/index/docid/548585/filename/cvpr06_lana.pdf) ⼀样连接起来。 SPPnet 在测试时将 R-CNN 加速了 10 到 100 倍。由于更快的提议特征提取，训练时间也减少了 3 倍。

- SPPnet 也有明显的缺点。与 R-CNN ⼀样，训练是⼀个多阶段流⽔线，涉及提取特征、使⽤对数损失微调⽹络、训练 SVM，最后拟合边界框回归器。功能也写⼊磁盘。但与 R-CNN 不同的是，[SPPnets](https://www.semanticscholar.org/reader/cbb19236820a96038d000dc629225d36e0b6294a)中提出的微调算法⽆法更新空间⾦字塔池之前的卷积层。毫不奇怪，这种限制（固定卷积层）限制了⾮常深的⽹络的准确性。


# 二、做出的创新
1. 我们提出了⼀种新的训练算法，修复了 R-CNN 和 SPPnet 的缺点，同时提⾼了它们的速度和准确性。我们将此⽅法称为 Fast R-CNN，因为它的训练和测试速度相对较快。 Fast R CNN⽅法有⼏个优点：
    1. ⽐R-CNN、SPPnet更⾼的检测质量（mAP）

    2. Training is single-stage, using a multi-task loss

    3. 训练可以更新所有⽹络层

    4. 特征缓存不需要磁盘存储

2. 使用的主干网络是VGG16网络

# 三、设计的模型
1. Fast R-CNN 架构
    ![Fast R-CNN1.png](../pictures/Fast%20R-CNN/Fast%20R-CNN1.png)

    - Fast R-CNN ⽹络将整个图像和⼀组⽬标建议作为输⼊。该⽹络⾸先使⽤多个卷积 (conv) 和最⼤池化层处理整个图像，以⽣成⼀个 conv 特征图。然后，对于每个⽬标提议，⼀个感兴趣区域 (RoI) 池化层从特征图中提取⼀个固定⻓度的特征向量。每个特征向量被送⼊⼀系列全连接 (fc) 层，最终分⽀成两个同级输出层：⼀个产⽣ K 个对象类的 softmax 概率估计加上⼀个包罗万象的“背景”类，另⼀个层输出四个K 个对象类中的每⼀个的实数值。每组 4 个值为 K 个类之⼀编码精细的边界框位置。

2. RoI池化层
    - RoI 池化层使⽤最⼤池化将任何有效感兴趣区域内的特征转换为具有固定空间范围 $H \times W$（例如，7 × 7）的⼩特征图，其中 $H$ 和 $W$ 是层超参数独⽴于任何特定的 RoI。在本⽂中，RoI 是转换特征图的矩形窗⼝。每个 RoI 由⼀个四元组 $(r, c, h, w)$ 定义，指定其左上⻆ $(r, c)$ 及其⾼度和宽度 $(h, w)$ 。

    - RoI max pooling 的⼯作原理是将 $h \times w$ RoI 窗⼝划分为 $H \times W$ ⼤⼩近似为 $h/H \times w/W$ 的⼦窗⼝⽹格，然后将每个⼦窗⼝中的值最⼤池化到相应的输出⽹格中细胞。与标准最⼤池化⼀样，池化独⽴应⽤于每个特征图通道。 RoI 层只是 [SPPnets](https://www.semanticscholar.org/reader/cbb19236820a96038d000dc629225d36e0b6294a) 中使⽤的空间⾦字塔池层的特例，其中只有⼀个⾦字塔级别。我们使⽤ [SPPnets](https://www.semanticscholar.org/reader/cbb19236820a96038d000dc629225d36e0b6294a) 中给出的池化⼦窗⼝计算。

3. 从预训练⽹络初始化
    - 我们⽤三个预训练的 [ImageNet](http://vision.stanford.edu/pdf/ImageNet_CVPR2009.pdf) ⽹络进⾏实验，每个都有五个最⼤池化层和 5 到 13 个 conv 层（有关⽹络细节，请参⻅第4.1节）。当预训练⽹络初始化 Fast R-CNN ⽹络时，它会经历三个转换。

    - ⾸先，最后⼀个最⼤池化层被 RoI 池化层替换，该层通过设置 $H$ 和 $W$ 来配置以与⽹络的第⼀个全连接层兼容（例如，对于 VGG16， $H = W = 7$ ）。

    - 其次，⽹络的最后⼀个全连接层和 softmax（为 1000 路 ImageNet 分类训练）被替换为前⾯描述的两个兄弟层（⼀个全连接层和 softmax 在 K + 1 个类别和类别特定的边界上-框回归器）。

    - 第三，⽹络被修改为接受两个数据输⼊：图像列表和这些图像中的 RoI 列表。

4. 检测微调
    - 使用反向传播训练所有网络权重是Fast R-CNN的一项重要功能。首先，让我们解释为什么SPPnet无法更新空间金字塔池层以下的权重。根本原因是，当每个训练样本（即RoI）来自不同的图像时，通过SPP层的反向传播效率很低，这正是R-CNN和SPPnet网络的训练方式。低效率源于这样一个事实，即每个RoI可能具有非常大的感受野，通常跨越整个输入图像。由于前传必须处理整个感受野，训练输入很大（通常是整个图像）

    - 我们提出了⼀种更有效的训练⽅法，该⽅法在训练期间利⽤特征共享。在 Fast R CNN 训练中，随机梯度下降 (SGD) mini batches 是分层采样的，⾸先采样 N 个图像，然后从每个图像采样 $R/N$ RoIs。⾄关重要的是，来⾃同⼀图像的 RoI 在前向和反向传递中共享计算和内存。使 N 变⼩会减少⼩批量计算。例如，当使⽤ $N = 2$ 和 $R = 128$ 时，所提出的训练⽅案⽐从 128 个不同图像中采样⼀个 RoI（即 R-CNN 和 SPPnet 策略）快⼤约 64 倍。

    - 对该策略的⼀个担忧是它可能会导致训练收敛缓慢，因为来⾃同⼀图像的 RoI 是相关的。这个问题似乎不是⼀个实际问题，我们在 N = 2 和 R = 128 时使⽤⽐ R-CNN 更少的 SGD 迭代取得了良好的结果。

    - 除了分层采样之外，Fast R-CNN 使⽤简化的训练过程和⼀个微调阶段联合优化 softmax 分类器和边界框回归器，⽽不是在三个单独的阶段训练 softmax 分类器、SVM 和回归器([R-CNN](https://arxiv.org/pdf/1311.2524v5.pdf)和[SPPnet](https://www.semanticscholar.org/reader/cbb19236820a96038d000dc629225d36e0b6294a))。这个过程的组成部分（损失、⼩批量采样策略、通过 RoI 池化层的反向传播和 SGD 超参数）在下⾯描述。

    - 多任务损失。 Fast R-CNN ⽹络有两个同级输出层。第⼀个输出离散概率分布（每个 RoI），$p = (p_ {0},..., p_ {K})$ ，超过 $K + 1$ 个类别。像往常⼀样，$p$ 由全连接层的 $K+1$ 个输出上的 softmax 计算得出。第⼆个兄弟层输出边界框回归偏移量 $t^{k} = (t^{k}_ {x},t^{k}_ {y},t^{k}_ {w},t^{k}_ {h})$ ，⽤于 $K$ 个对象类中的每⼀个，由 $k$ 索引。我们使⽤R-CNN中给出的 $t^{k}$ 的参数化，其中 $t^{k}$ 指定了相对于⽬标提议的尺度不变平移和对数空间⾼度/宽度偏移。
        - 每个训练 RoI 都标有真实类别 $u$ 和真实边界框回归⽬标 $v$ 。我们在每个标记的 RoI 上使⽤多任务损失 $L$ 来联合训练分类和边界框回归：
            $$\begin{align}
            L(p,u,t^{u},u) = L_ {cls}(p,u) + \lambda[u \ge 1]L_ {loc}(t^{u}, v)
            \end{align}$$
            其中， $L_ {cls}(p,u) = -logp_ {u}$是真实类 u 的对数损失。
        
        - 第二个任务损失 $L_ {loc}$ 是在类 $u$ 的真边界框回归目标的元组上定义的， $v = (v_ {x}，v_ {y}，v_ {w}，v_ {h})$ ，以及类 $u$ 的预测元组 $t^{u} = (t^{u}_ {x},t^{u}_ {y},t^{u}_ {w},t^{u}_ {h})$ 。当 $u \ge 1$ 时，艾弗森支架指示器函数 $[u \ge 1]$ 的值为1，否则为0。按照惯例，catch-all背景类标记为 $u = 0$ 。对于背景RoI，没有地面真实边界框的概念，因此Lloc被忽略。对于边界框回归，我们使用损失：
            $$\begin{align}
            L_ {loc}(t^{u},v) = \sum_ {i \in \lbrace x,y,w,h \rbrace} smooth_ {L_ {1}}(t^{u}_ {i} - v_ {i})
            \end{align}$$
            其中，
            $$\begin{align}
            smooth_ {L_ {1}}(x) = \left\{ 
            \begin{aligned}
            &0.5x^{2}   &   &\mathbf{if}|x| < 1 \\
            &|x| - 0.5  &   &otherwise, 
            \end{aligned}
            \right.
            \end{align}$$
            是⼀种稳健的 $L_ {1}$ 损失，与R-CNN 和 SPPnet 中使⽤的 $L_ {2}$ 损失相⽐，它对异常值的敏感性较低。当回归⽬标⽆界时，使⽤ $L_ {2}$ 损失进⾏训练可能需要仔细调整学习率以防⽌梯度爆炸。当然，公式3消除了这种敏感性。
        
        - 等式1中的超参数 $\lambda$ 控制两个任务损失之间的平衡。我们将地面真实回归目标 $v_ {i}$ 归一化为零均值和单位方差。所有实验均使用 $λ=1$ 。

        - 我们注意到[ImageNet: A large-scale hierarchical image database](https://www.semanticscholar.org/reader/67fc0ec1d26f334b05fe66d2b7e0767b60fb73b6)使⽤相关损失来训练类不可知对象提议⽹络。与我们的⽅法不同， [ImageNet: A large-scale hierarchical image database](https://www.semanticscholar.org/reader/67fc0ec1d26f334b05fe66d2b7e0767b60fb73b6)提倡将定位和分类分开的双⽹络系统。 [OverFeat](https://arxiv.org/pdf/1312.6229.pdf)、 R-CNN 和 SPPnet 也训练分类器和边界框定位器，但是这些⽅法使⽤阶段式训练，我们证明这对 Fast R-CNN 来说是次优的（第5.1节）。
    
    - ⼩批量抽样。在微调期间，每个 SGD mini-batch 由 N = 2 个图像构成，随机选择统⼀（按照惯例，我们实际上迭代了数据集的排列）。我们使⽤⼤⼩为 $R = 128$ 的⼩批量，从每个图像中采样 64 个 RoI。与R-CNN中⼀样，我们从对象建议中提取 25% 的 RoI，这些对象建议具有交集（IoU）与⾄少 0.5 的地⾯实况边界框重叠。这些 RoIs 包括⽤前景对象类标记的⽰例，即 $u \ge 1$ 。其余 RoIs 从具有最⼤ IoU 的对象提案中采样，在区间 $[0.1, 0.5)$ 内，遵循SPPnet。这些是背景⽰例，并标有 $u = 0$ 。0.1 的下限阈值似乎可以作为难⽰例挖掘的启发式[Object detection with discriminatively trained part based models](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5255236)。在训练期间，图像以 0.5 的概率⽔平翻转。没有使⽤其他数据增强。

    - 通过 RoI 池化层反向传播。反向传播通过 RoI 池化层路由导数。为清楚起⻅，我们假设每个⼩批量只有⼀张图像 $（N = 1）$ ，尽管 $N > 1$ 的扩展很简单，因为前向传递独⽴处理所有图像。
        - 令 $x_ {i} \in R$ 为 RoI 池化层的第 $i$ 个激活输⼊，并令 $y_ {rj}$ 为第 $r$ 个 RoI 的层的第 $j$ 个输出。RoI 池化层计算 $y_ {rj} = x_ {i^{*}(r, j)}$ 其中 $i^{*}(r, j) = argmax_ {i^{'} \in \mathcal{R}(r,j)} x_ {i^{'}} $ 。$\mathcal{R}(r, j)$ 是子窗口中输入的索引集，输出单元 $y_ {rj}$ 最大池化。单个 $x_ {i}$ 可以分配给多个不同的输出 $y_ {rj}$。

        - RoI 池化层的反向传播函数通过遵循 argmax 开关计算损失函数相对于每个输⼊变量 $x_ {i}$ 的偏导数：
            $$\begin{align}
            \frac{\partial L}{\partial x_ {i}} = \sum_ {r}\sum_ {j}[i=i^{*}(r,j)]\frac{\partial L}{\partial y_ {rj}}
            \end{align}$$

        - 换言之，对于每个小批量RoI $r$ 和每个池化输出单位 $y_ {rj}$ ，如果 $i$ 是通过最大池化为 $y_ {rj}$ 选择的argmax，则会累积偏导数 $\frac{\partial L}{\partial y_ {rj}}$ 。在反向传播中，已经通过RoI池层顶部的层的反向函数计算了偏导数 $\frac{\partial L}{\partial y_ {rj}}$ 

    - SGD 超参数。⽤于 softmax 分类和边界框回归的全连接层分别从标准差为 0.01 和 0.001 的零均值⾼斯分布初始化。偏差被初始化为 0。所有层使⽤每层学习率 1 的权重和 2 的偏差和 0.001 的全局学习率。在 VOC07 或 VOC12 trainval 上训练时，我们运⾏ SGD 进⾏ 30k ⼩批量迭代，然后将学习率降低到 0.0001 并训练另外 10k 次迭代。当我们在更⼤的数据集上训练时，我们运⾏ SGD 进⾏更多迭代，如后所述。使⽤ 0.9 的动量和 0.0005 的参数衰减（关于权重和偏差）。

5. 尺度不变性
    - 我们探索了两种实现尺度不变⽬标检测的⽅法：（1）通过“蛮⼒”学习和（2）通过使⽤图像⾦字塔。这些策略遵循 SPPnet 中的两种⽅法。在蛮⼒⽅法中，每张图像在训练和测试期间都以预定义的像素⼤⼩进⾏处理。⽹络必须直接从训练数据中学习尺度不变的⽬标检测。
    
    - 相⽐之下，多尺度⽅法通过图像⾦字塔为⽹络提供近似的尺度不变性。在测试时，图像⾦字塔⽤于近似缩放归⼀化每个⽬标提议。在多尺度训练期间，我们在每次对图像进⾏采样时随机采样⼀个⾦字塔尺度，遵循 SPPnet ，作为数据增强的⼀种形式。由于 GPU 内存限制，我们仅对较⼩的⽹络进⾏多尺度训练实验。

6. 快速R-CNN检测
    - ⼀旦对 Fast R-CNN ⽹络进⾏了微调，检测就相当于运⾏前向传递（假设⽬标提议是预先计算的）。该⽹络将图像（或图像⾦字塔，编码为图像列表）和要评分的 $R$ 对象建议列表作为输⼊。在测试时间， $R$ 通常在 2000 左右，尽管我们会考虑它更⼤ ( $\approx 45k$ ) 的情况。当使⽤图像⾦字塔时，每个 RoI 都被分配给尺度，使得缩放后的 RoI在区域 SPPnet 中最接近 $224^{2}$ 个像素。

    - 对于每个测试 RoI $r$ ，前向传递输出类后验概率分布 $p$ 和⼀组相对于 $r$ 的预测边界框偏移量（$K$ 个类中的每⼀个都有⾃⼰的精确边界框预测）。我们使⽤估计的概率 $Pr(class = k | r) \triangleq p_ {k}$ 为每个对象类别 $k$ 为 $r$ 分配⼀个检测置信度。然后，我们使⽤ R-CNN 的算法和设置为每个类独⽴执⾏⾮最⼤抑制。

    1. 截断 SVD 以加快检测速度
        - 对于整个图像分类，与对流层相比，计算完全连接层所花费的时间很短。相反，对于检测，要处理的RoI数量很大，近一半的正向通过时间用于计算完全连接的层（见图2）。通过用截断SVD压缩大的完全连接层，可以容易地加速它们。
            ![Fast R-CNN2.png](../pictures/Fast%20R-CNN/Fast%20R-CNN2.png)

        - 在这种技术中，由 $u \times v$ 参数化的层权重矩阵 $W$ 近似分解为
            $$\begin{align}
            W \approx U \Sigma_ {t} V^{T}
            \end{align}$$
            使用SVD。在这种分解中， $U$ 是一个 $U \times t$ 矩阵，包括 $W$ 的前 $t$ 个左奇异向量， $\Sigma_ {t}$ 是一个 $t \times t$ 对角矩阵，包含 $W$ 的前 $t$ 个奇异值， $V$ 是 $V \times t$ 矩阵。为了压缩网络，对应于 $W$ 的单个完全连接层被两个完全连接的层代替，它们之间没有非线性。第一层使用权重矩阵 $\Sigma_ {t}V^{T}$ （无偏差），第二层使用 $U$ （原始偏差与W相关）。当RoI数量较大时，这种简单的压缩方法可以提供良好的加速。

# 四、实验结果
1. 三个主要结果⽀持本⽂的贡献：
    1. VOC07、2010 和 2012 上最先进的 mAP
    1. 与 R-CNN、SPPnet 相⽐，训练和测试速度更快
    1.  VGG16 中的微调卷积层提⾼了 mAP

2. 我们的实验使⽤三个可在线获得的预训练 ImageNet 模型。
    1. 第⼀个是来⾃ R-CNN 的 CaffeNet（本质上是 AlexNet ） 。我们也可以参考将此 CaffeNet 作为模型S，表⽰“⼩”。
    1. 第⼆个⽹络是VGG_CNN_M_1024，它具有与 $\mathbf{S}$ 相同的深度，但更宽。我们将此⽹络模型称为 $\mathbf{M}$ ，表⽰“媒介”。最终⽹络是⾮常深的 VGG16 模型。由于这个模型是最⼤的，我们称它为模型 $\mathbf{L}$ 。在本节中，所有实验都使⽤单尺度训练和测试（s = 600；详⻅5.2节）。

3. 微调哪些层？
    - 对于 SPPnet 论⽂中考虑的不太深的⽹络，仅对完全连接的层进⾏微调似乎⾜以获得良好的准确性。我们假设这个结果不适⽤于⾮常深的⽹络。为了验证微调 conv 层对 VGG16 很重要，我们使⽤ Fast R-CNN 进⾏微调，但冻结了 13 个 conv 层，以便只有完全连接的层学习。这种消融模拟了单尺度 SPPnet 训练并将 mAP 从 66.9% 降低到 61.4% 。这个实验验证了我们的假设：通过 RoI 池化层进⾏训练对于⾮常深的⽹络很重要。

    - 这是否意味着所有的转换层都应该微调？

    - 简⽽⾔之，不。在较⼩的⽹络（S和M）中，我们发现 conv1 是通⽤的并且与任务⽆关（众所周知的事实[14]）。允许 conv1 学习与否，对 mAP 没有任何有意义的影响。对于 VGG16，我们发现只需要从 conv3 1 及以上（13 个 conv 层中的 9 个）更新层。这个观察是务实的：（1）与从 conv3 1 学习相⽐，从 conv2 1 更新训练减慢了 1.3 倍（12.5 对 9.5 ⼩时）； (2) 从 conv1 1 更新会超出 GPU 内存。从 conv2 1 向上学习时，mAP 的差异仅为 +0.3 点（表5，最后⼀列）。本⽂中的所有 Fast R-CNN 结果均使⽤ VGG16 微调层 conv3 1 及以上；模型S和M的所有实验都对 conv2 及以上层进⾏了微调。
## 1、比之前模型的优势

## 2、有优势的原因
1. 多任务训练有帮助吗？
    - 多任务训练很⽅便，因为它避免了管理顺序训练任务的管道。但它也有可能改善结果，因为任务通过共享表⽰（ConvNet）相互影响。多任务训练是否提⾼了 Fast R-CNN 中的⽬标检测精度？
    - 在所有三个⽹络中，我们观察到多任务训练相对于单独的分类训练提⾼了纯分类的准确性。改进范围从 +0.8 到 +1.1 mAP 点，表明多任务学习具有⼀致的积极效果。
    - 最后，我们采⽤基线模型（仅使⽤分类损失进⾏训练），添加边界框回归层，并使⽤Lloc对其进⾏训练，同时保持所有其他⽹络参数不变。每组中的第三列显⽰了这种分阶段训练⽅案的结果：mAP ⽐第⼀列有所改进，但分阶段训练执⾏多任务训练（每组第四列）。

2. 尺度不变性：蛮⼒还是技巧？
    - 我们⽐较了实现尺度不变⽬标检测的两种策略：蛮⼒学习（单尺度）和图像⾦字塔（多尺度）。⽆论哪种情况，我们都将图像的尺度 s 定义为其最短边的⻓度。 
    - 也许SPPnet中最令⼈惊讶的结果是单尺度检测的性能⼏乎与多尺度检测⼀样好。我们的调查结果证实了他们的结果：深度卷积神经⽹络擅⻓直接学习尺度不变性。多尺度⽅法仅以⼤量计算时间为代价提供了 mAP 的⼩幅增加。在 VGG16（模型 L）的情况下，我们被实施细节限制为使⽤单⼀尺度。然⽽，它实现了 66.9% 的 mAP，略⾼于 R-CNN 报告的 66.0%，尽管 R-CNN 在每个提议都被扭曲到规范⼤⼩的意义上使⽤“⽆限”尺度。
    - 由于单尺度处理在速度和准确性之间提供了最佳折衷，特别是对于⾮常深的模型，因此本⼩节之外的所有实验都使⽤ s = 600 像素的单尺度训练和测试。

3. 需要更多的训练数据吗？
    - 当提供更多训练数据时，⼀个好的⽬标检测器应该会有所改进。发现 DPM mAP 在仅⼏百到⼏千个训练⽰例后就饱和了。在这，我们使⽤ VOC12 trainval 集扩充 VOC07 trainval 集，将图像数量⼤致增加三倍⾄ 16.5k，以评估 Fast R-CNN。扩⼤训练集可将 VOC07 测试中的 mAP 从 66.9% 提⾼到 70.0% 。在这个数据集上训练时，我们使⽤ 60k mini-batch 迭代⽽不是 40k。
    - 我们对 VOC10 和 2012 进⾏了类似的实验，为此我们从 VOC07 trainval、test 和 VOC12 trainval 的联合构建了⼀个包含 21.5k 图像的数据集。在这个数据集上训练时，我们使⽤ 100k SGD 迭代，每 40k 迭代（⽽不是每 30k）将学习率降低 0.1×。对于 VOC10 和 2012，mAP 分别从 66.1% 提⾼到 68.8% 和从 65.7% 提⾼到 68.4%。

4. SVM 是否优于 softmax？
    - Fast R-CNN 使⽤在微调期间学习的 softmax 分类器，⽽不是训练⼀对⼀的线性 SVM 后，就像在 R-CNN 和 SPPnet 中所做的那样。为了了解这种选择的影响，我们在 Fast R-CNN 中实施了具有硬负挖掘的事后 SVM 训练。我们使⽤与 R-CNN 相同的训练算法和超参数。
    - softmax 在所有三个⽹络中的表现略优于 SVM，+0.1 到 +0.8 mAP 点。这种效果很⼩，但它表明与以前的多阶段训练⽅法相⽐，“⼀次”微调就⾜够了。我们注意到，与 one-vs-rest SVM 不同，softmax 在对 RoI 评分时引⼊了类之间的竞争。

5. 提案越多越好吗？
    - 我们发现随着提案数量的增加，mAP 上升然后略微下降。这个实验表明，⽤更多的建议淹没深度分类器⽆助于甚⾄轻微损害准确性。
## 3、改进空间

# 五、结论

## 1、模型是否解决了目标问题

## 2、模型是否遗留了问题

## 3、模型是否引入了新的问题

# 六、代码

# 读者角度（挖掘文章中没有提到的）：
1. 总结文章发现问题的思路
2. 总结文章改进的思想
3. 总结文章还存在或者可以改进的问题
4. 提出对模型参数和细节的一些思考和讨论