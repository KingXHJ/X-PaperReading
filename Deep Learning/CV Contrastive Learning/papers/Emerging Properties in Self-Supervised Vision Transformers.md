# 论文信息
- 时间：2021
- 期刊：ICCV
- 网络/算法名称：DINO
- 意义：transformer加自监督在视觉也很香
- 作者：Mathilde Caron, Hugo Touvron, Ishan Misra, Hervé Jégou, Julien Mairal, Piotr Bojanowski, Armand Joulin
- 实验环境：
- 数据集：
- [返回上一层 README](../README.md)

## 导读

`DINO` 是一种用于自监督视觉学习的深度学习模型，于 2021 年由 `Facebook AI` 提出。DINO 是最先探讨基于 `Transformer` 架构的自监督学习代表作之一，其通过在无标签图像上进行自监督训练来学习视觉特征表示。

相比于监督学习需要人为地提供标签告诉模型这是什么，自监督学习无须任何“显示”标签，只需输入图像通过某种机制便能让网络学会理解图像本身的语义信息。例如，我们可以通过图像旋转、随机裁剪等变换，使模型学习到不同角度、不同尺度下的特征。另外，也可以通过模型自身的预测来构建任务，例如预测图像的局部块、颜色等等。这些任务由于不需要人类标注，因此可以在大规模的无标签数据上进行训练，从侧面上提供了一种从无标签数据中学习特征表示的新方法，它可以帮助我们更好地利用现有数据资源，解决监督学习中的一些瓶颈问题。

回到正题，DINO 的核心思想便是通过在大规模的无标签数据集上进行对比学习，学习出一组具有可传递性的视觉特征表示。在 DINO 中，作者通过引入一个新的对比学习方法，将原始图像的特征与随机裁剪的图像的特征进行对比，从而学习到更好的视觉通用表征，最终也获得了非常出色的效果。

![DINO outcome](../pictures/DINO/DINO%20outcome.png)

> DINO 这个名称可以理解为是由 Distillation 和 NO labels 这两个词组成的缩写，既表达了DINO采用自蒸馏方法的特点，也突出了它是一种基于无监督学习的模型。具体来说，DINO 是使用一种称为“无监督自蒸馏”的方法，该方法通过自监督学习来学习模型的知识表示。在这个方法中，模型使用自身的输出来生成“伪标签”，然后使用这些伪标签来重新训练模型，从而进一步提高模型的性能和泛化能力。

## 方法

作为开始，我们给出一张动图，其非常生动形象的展示了贯穿 DINO 的整个框架和核心思想：

![DINO mind](../pictures/DINO/DINO%20mind.gif)

如上所示，DINO 本质上是一种自监督学习方法，通过无监督的方式学习图像特征表示，可用于计算机视觉的其他下游任务，例如分类和检测等。该方法的核心思想是使用一种叫做自蒸馏的方法，即将一个学生模型的表示与一个动量化的教师模型的表示进行比较，以学习出更好的特征表示。

在正式讲解具体细节前，我们可以先看看 DINO 整个处理流程的伪代码：

![DINO pseudo code](../pictures/DINO/DINO%20pseudo%20code.png)

下面我们将分别从网络结构、数据增强、损失函数三大部分进行详细的介绍。

### 网络结构

正如我们上面提到过的，DINO 是采用自蒸馏(`self-distillation`)的方法学习的，其整体框架包含两个相同的架构，分别为教师网络和学生网络，具体的架构可以是 ViT 等 vision transformer 或者诸如 ResNet 等 CNNs 特征提取器，非常灵活方便。当然，通过下述消融实验也知道还是 ViT 的潜力更大。

![DINO fusion experiment](../pictures/DINO/DINO%20fusion%20experiment.png)

然而，这种学生和教师网络均输出相同 `embeddings` 的情况容易出现模式崩塌(`mode collapse`)的现象。在《`Momentum Contrast for Unsupervised Visual Representation Learning`》一文中提出了一种解决方案，即应用“动量教师”(`momentum tearcher`)模型，可以简单地理解为就是教师的模型不是基于反向传播更新的，而是再对学生模型进行梯度回传后，在通过指数移动平均(`Exponential Moving Average, EMA`)，直接将学生网络学习到的模型参数更新给教师网络，换句话就是教师网络的权重更新自学生网络。

DINO 中便是沿用这种方式。具体地，我们可以简单看下教师权重的更新公式：

![DINO distillation teacher optimizer function](../pictures/DINO/DINO%20distillation%20teacher%20optimizer%20function.png)

这里下标 $t$ 和 $s$ 分别指代教师和学生网络对应的模型参数；而 $\lambda$ 则跟随余弦学习率衰减策略在训练过程中从 0.996 到 1 之间进行变化。

### 数据增强

DINO 中最核心的数据采样策略便是图像裁剪，这也是自监督学习领域应用非常广泛的主策略之一。一般来说，我们可以将裁剪后的图像分为两种：

- `Local views`: 即**局部视角**，也称为 small crops，指的是抠图面积小于原始图像的 50%；
    
- `Global views`: 即**全局视角**，也称为 large crops，指的是抠图面积大于原始图像的 50%；
    

在 DINO 中，学生模型接收所有预处理过的 crops 图，而教师模型仅接收来自 global views 的裁剪图。据作者称，这是为了鼓励从局部到全局的响应，从而训练学生模型从一个小的裁剪画面中推断出更广泛的上下文信息。

> 简单来说，就是把局部特征和全局特征分别交给不同的模型来学习，以便在处理整个图像时，能够更好地对局部细节和上下文进行综合判断。

此外，为了使网络更加鲁邦，DINO 中也采用一些其它的随机增强，包括：

- **颜色扰动**(`color jittering`)
    
- **高斯模糊**(`Gaussian blur`)
    
- **曝光增强**(`solarization`)
    

### 损失函数

在 DINO 中，教师和学生网络分别预测一个一维的嵌入。为了训练学生模型，我们需要选取一个损失函数，不断地让学生的输出向教师的输出靠近。softmax 结合交叉熵损失函数是一种常用的做法，来让学生模型的输出与教师模型的输出匹配。具体地，通过 softmax 函数把教师和学生的嵌入向量尺度压缩到 0 到 1 之间，并计算两个向量的交叉熵损失。这样，在训练过程中，学生模型可以通过模仿教师模型的输出来学习更好的特征表示，从而提高模型的性能和泛化能力。

当然，这也可以看作是一个分类问题，以便网络可以从局部视图中学习更有意义的全局表示。

![DINO flow](../pictures/DINO/DINO%20flow.png)


### Centering and Sharpening

在 DINO 论文中，还有两个不得不提的点便是 `Centering` 和 `Sharpening`，这是用于防止模式崩塌的两种有效方式。

> 在自监督学习中，mode collapse 是指网络的学习过程中出现了多样性减少的现象。具体来说，当网络学习到一组特征表示时，往往会出现多个输入数据映射到相同的特征表示的情况，这就是所谓的模式崩塌。这种现象通常是由于网络在优化过程中陷入了局部最优解，只能考虑到一部分数据的特征表示，而忽略了其它数据样本的模式和特征，从而导致了多样性缺失的现象，因此会对模型的鲁棒性产生很大的负面影响。

先来看下 `Centering`。首先，教师模型的输出经过一个 EMA 的操作，从原始激活值中减去得到一个新的结果。简单来说，可以表述为下列公式：$$Logits = Logits - Logits_ {mwan}$$

这个操作的目的是使得激活值有时候是正的（当它们高于平均值时），有时候是负的（当它们低于平均值时）。由于 softmax 函数在处理负数时会给出较小的概率值，而在处理正数时会给出较大的概率值，因此这种操作能够防止任何一个特征占据统治地位，因为平均值会在值的范围中间。

最后，再看看 `Sharpening`。这种技巧通过在 softmax 函数中加入一个 temperature 参数，来强制让模型将概率分布更加尖锐化。由于小差异会被夸大，这会防止所有激活值都是相同的，因为小的差异也会被放大。这个技巧和中心化操作搭配使用，可以使得激活值不断变化，从而引导学生模型更好地了解哪些特征应该变得更加强大。

## 实验

首先，看下这张效果图：

![DINO outcome monkey](../pictures/DINO/DINO%20outcome%20monkey.png)

可以看出，DINO 是能够自动学习特定于类别(`class-specific`)的特征，从而实现准确的无监督对象分割。

其次，我们将此模型应用于未受过训练的场景，例如用于识别重复图像：

![DINO find repeat picture](../pictures/DINO/DINO%20find%20repeat%20picture.png)

可以看出，DINO 的表现也优于现有的最先进模型，尽管它起初并不是为这一目的设计的！

![DINO object detection](../pictures/DINO/DINO%20object%20detection.png)

通过以上可视化结果不难看出，相比于监督学习，DINO 的潜在空间也具有很好的分离类别，这意味着它的特征足够丰富，可以分离物体中的微小差异，这使得它非常适合下游任务和迁移学习。

最后，我们通过 t-SNE 可视化一起看看 DINO 的整个学习表征过程：

![DINO how it learned](../pictures/DINO/DINO%20how%20it%20learned.gif)

Amazing!

## 总结

本文主要向大家介绍 DINO，这是第一篇探索 ViT 模型在自监督学习领域的经典代表作。DINO 整体架构基于自蒸馏的范式进行构建，包含一个教师网络和学生网络。其中，学生网络学习从局部补丁预测图像中的全局特征，该补丁受动量教师网络嵌入的交叉熵损失的监督，同时进行居中和锐化以防止模式崩溃。
