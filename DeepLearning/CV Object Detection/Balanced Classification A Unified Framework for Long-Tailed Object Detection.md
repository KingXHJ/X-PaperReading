# 论文信息
- 时间：2023
- 期刊：CVPR
- 网络/算法名称：BACL
- 意义：解决长尾目标检测的统一框架
- 作者：Tianhao Qi, Hongtao Xie*, Pandeng Li, Jiannan Ge and Yongdong Zhang, Senior Member, IEEE
- 实验环境：
- 数据集：
# 一、解决的问题
- 传统的检测器在处理长尾数据时，由于对大多数头部类别的分类偏差而导致性能下降。本文认为，学习偏差源于两个因素: 1)前景类别分布不平衡导致的不平等竞争; 2)尾部类别缺乏样本多样性。为了解决这些问题，我们引入了一个称为平衡分类(BACL)的统一框架，该框架能够自适应地纠正由类别分布差异和样本多样性动态增强引起的不平等。具体而言，本文提出了一种新的前景分类平衡损失(FCBL)方法，通过分别引入双分类感知边距和自动调整权重项，改善头部类别的统治地位，并将注意力转移到难以区分的类别上。这种损失防止了在不平等竞争背景下对尾部类别的过度抑制。此外，我们提出了一个动态特征幻觉模块(FHM)，该模块通过合成幻觉样本来引入额外的数据方差来增强尾部类别在特征空间中的表示。在这种分而治之的方法中，BACL通过分离的训练管道在具有挑战性的LVIS基准上设置了新的最先进的技术，在总体和尾部类别上超过了具有ResNet-50-FPN的更快R-CNN, AP分别为5.8%和16.1%。大量的实验表明，BACL在具有不同主干和架构的各种数据集上始终如一地实现性能改进。
- 最近，深度神经网络在平衡良好的目标检测基准上显示出有希望的结果，如Pascal VOC和MS COCO。然而，与这些人为平衡的数据集相反，现实世界的数据表现出固有的长尾分布。也就是说，少数类别(头部类别)占据了绝大多数样本，而剩下的许多类别(尾部类别)只对应了一小部分样本，如图1(a)所示。这种倾斜的分布不可避免地给数据饥渴的深度神经网络带来了巨大的挑战。不幸的是，当前基于深度学习的检测器（例如，Faster R-CNN[13]）在遇到像LVIS[14]这样的长尾数据集时，性能下降，尤其是在代表性不足的尾部类别上，后者更像真实世界场景。这种不希望的性能退化严重影响了基于深度学习的检测器的实用性，从而阻碍了相关技术的进步。因此，探索有效的训练策略来应对长尾目标检测引起了广泛的研究兴趣。
![BACL1](./picture/BACL1.png)

- 为了在现实场景中提高性能，开创性的工作广泛研究了训练数据中的长尾分布对两级检测器(即Faster R-CNN)的各个组成部分的不利影响。这些研究一致认为，严重偏向头部类别的分类器是影响检测指标的主要瓶颈。因此，减轻分类偏差已成为长尾目标检测的一个突出趋势。
- 为此，一个直观的解决方案是重新平衡训练分布。有些作品通过图像级或对象级重采样来实现这一目标。另一项研究探索了针对分类损失的专门裕度设计或重新加权策略，旨在模拟更平衡的训练集。除了数据重新平衡之外，还提出了几种新的检测器架构，将有价值的先验知识纳入训练过程。与这些方法正交，Kang等人创造性地将学习过程解耦为长尾图像分类的表示学习和分类器学习阶段，极大地提高了准确性。这种两阶段解耦的训练流水线在长尾对象检测中也被证明是有效的，并应用于后续的研究。
- 然而，现有的大多数方法主要侧重于减轻前景类别之间的不平等竞争，而忽略了尾部类别代表性不足的潜在问题。从本质上讲，它们忽略了增强尾类别训练实例的多样性。因此，缺乏样本变化破坏了分类器对尾部类别的区分能力，限制了检测性能的进一步提高。
- 为了进一步提升服务表现，我们采取分而治之的方法，兼顾这两个问题:
    1. 由于频率极不平衡而引起的前景类别之间的不平等竞争;
    1. 尾部类别代表性不足的潜在问题，其特征是缺乏不同的视觉实例。
- 为了解决这些问题，我们引入了一个统一的框架，称为平衡分类(BACL)，如图2所示，基于上述解耦学习方案。为了方便去偏，BACL使用一对长期和短期指标，从两个不同的角度监测分类器的学习状态:对前景类别的分类倾向和对每个类别的分类正确性。
![BACL2](./picture/BACL2.png)

- 基于这对指标，我们将两个关键部分整合到拟议的框架中。首先，我们引入了一种新的前景分类平衡损失(FCBL)来感知前景类别之间的差异，并通过两两分类感知边缘自适应改善头部类别对尾部类别的统治。FCBL还为每个非真实类别分配了一个自动调整的权重项，重点是难以区分的类别。这种加权策略有助于偏差校准，特别是考虑到大词汇数据集带来的学习困难。此外，我们提出了一个动态特征幻觉模块(FHM)来增强尾部类别在特征空间中的表示。该模块准确捕捉特征分布，并有选择性地选择倾向于尾部类别的类别，使用再参数化技巧合成幻觉特征，这引入了额外的数据方差。通过这两个成分的协同作用，BACL通过纠正类别分布差异引起的不平等和强化样本多样性来协同消除分类偏差，如图1(c)所示。
- 大量的长尾目标检测和实例分割实验证明了BACL的有效性。在具有挑战性的LVIS v0.5数据集上，BACL的性能大大优于基线模型，将总体精度从22.0%提高到27.8%，AP提高5.8%。改善主要体现在罕见类别(+16.1% AP)和常见类别(+7.0% AP)。BACL甚至将频繁类别的准确率略微提高了0.2%。更令人信服的是，它比所有现有的最先进的方法高出1.0%以上。

# 二、做出的创新
- 主要贡献概括如下:
    1. 我们引入一对互补的长期和短期指标，从两个角度监测分类器的学习状态，可以作为实时偏差校准的准确指导。
    1. 我们提出了一种两阶段解耦的长尾目标检测训练框架BACL，该框架结合了一种新的前景分类平衡损失来减轻前景类别之间的不平等竞争，以及一个动态特征幻觉模块来增强样本多样性，特别是尾部类别
    1. 各种设置的大量实验证明了BACL与基线和先前最先进的方法相比的优越性，以及其出色的泛化能力

- 深度学习模型出色的拟合能力极大地促进了目标检测领域的发展。然而，随着该领域研究的不断扩展，检测器在实际应用中遇到的长尾问题越来越受到关注。
1. General Object Detection
    - 基于预定义锚点的使用，现有的基于深度学习的对象检测器可以分为两组:基于锚点的和无锚点的。
    - 基于锚点的检测器包括两阶段和一阶段方法，采用各种尺度和位置的预定义锚点作为分类和回归的建议。R-CNN家族的出现巩固了两级探测器的主流地位。他们首先通过区域建议网络(RPN)在预定义锚点的基础上生成粗边界框建议，而建议智能预测头(Fast R-CNN)处理分类和位置优化任务。后续工作旨在通过融合多尺度特征、结合上下文信息、使用改进的训练策略以及应用注意机制来进一步提高性能。相比之下，基于单阶段锚定的检测器通过消除耗时的提案生成过程提供更高的效率。SSD将默认框分散在多个特征图的不同位置，并直接使用卷积神经网络来预测框偏移量和类别得分。后续的一级探测器，如RetinaNet和YOLO系列(原始的YOLO除外)都遵循了这一概念。
    - 然而，计算复杂度较高的基于锚点的检测器的性能对锚点的数量、尺寸和纵横比非常敏感。因此，近年来对无锚方法的研究日益突出，大致可分为两个分支。第一种方法是基于关键点，通过识别大量预先确定或自学习的关键点来生成边界框。第二种方法是基于中心的方法，它利用物体的中心点或区域来确定正实例，并预测从正实例到物体边界的四个距离。
1. Long-Tailed Object Detection
    - 为了处理目标检测中具有挑战性的长尾问题，目前的方法可以分为数据重采样，专门的损失设计，精致架构发明，解耦训练以及数据增强
    1. Data re-sampling
        - 重新采样是处理不平衡数据的常用解决方案，不平衡数据包括欠采样和过采样。然而，当头部和尾部类别之间的比例极度不平衡时，欠采样变得不可行的。相反，过度抽样增加了尾部类别样本的发生频率，同时保留了头部样本。在图像层面进行的过采样方法的例子包括类别感知采样和重复因子采样(RFS)。在对象层面，引入了一种公共记忆机制来重播尾部类别的过去特征，旨在平衡样本分布。然而，所有这些重抽样技术在提高尾部类别的样本多样性方面都有局限性。
    1. Specialized loss design
        - 专门的损失设计是解决长尾问题的另一种流行方法。Cui等提出了基于有效样本数调整分类损失比例的类平衡损失。均衡损失(Equalization loss, EQL)从损失梯度的角度创造性地分析了这一问题。它截断头部类别的负梯度，以减少对尾部类别预测的抑制，代价是将头部类别的实例错误地分类为尾部类别。为了改进对策，EQLv2根据累积的正、负梯度比，自适应地分别对每个类别的正梯度进行赋权，对负梯度进行赋权。此外，ACSL只惩罚过于自信的分数，以防止对尾部类别的过度抑制。Seesaw损失利用互补的缓解和补偿因子动态校准分类逻辑。同样，LOCE基于提出的平均分类分数自适应地调整分类逻辑。值得注意的是，虽然这些方法旨在通过强调尾类的重要性来模拟更平衡的训练集，但它们往往忽略了尾类别内有限的样本多样性问题
    1. Exquisite architecture invention
        - 人们一直在努力修改探测器的结构，以解决长尾分布问题。两个典型的代表是BAGS和Forest R-CNN，其目的是通过基于有价值的先验知识对所有类别进行分组来缓解头部类别对尾部类别的优势。不幸的是，他们优先解决前景类别之间的不平等竞争，而忽略了尾部类别样本的不足变化。
    1. Decoupled training
        - 解耦训练将检测器的训练过程分为两个阶段：表示学习和分类器学习。基于研究结果，即长尾分布在学习高质量表示时不是问题，一些工作将其方法应用于分类器学习阶段，以便只调整分类器，同时保持其他参数冻结。然而，分类器学习阶段的冻结特征提取器成为进一步改进的瓶颈，尤其是与端到端方法相比
    1. Data augmentation
        - 作为一种引入额外样本变化的有效方法，数据扩充有望在长尾分布的背景下补充未多样化的尾部类别。事实证明，适当的数据增强方法确实可以进一步改善长尾检测任务。最近提出的一种称为简单复制-粘贴的增强策略在改善解耦训练管道的特征表示方面显示出其优势。此外，FASA通过在特征空间中增加样本来解决数据稀缺问题，特别是尾部类别。然而，它不能准确地捕获所有类别的特征分布，并且涉及一个复杂的过程来间接更新待增强类别的采样概率
1. Feature hallucination
    - 特征幻觉是zero-shot识别任务中广泛采用的方法。这些研究利用基于类语义嵌入的生成对抗网络(GAN)来合成未见类的特征。然而，由于gan固有的不稳定性，训练一个辅助网络来生成尾部类别的各种特征是一项艰巨的任务。相比之下，我们提出的特征幻觉模块不涉及可训练参数和先验知识，如类语义嵌入。在检测器的训练过程中，它完全依赖于特征提取器的统计数据来一致地捕获每个类别的精确特征分布。同时，它根据我们提出的长期指标动态地为尾部类别分配更高的选择概率，并随后在每次迭代中执行特征合成过程。因此，特征幻觉模块效率很高，可以无缝集成到任何检测器中，为特征合成过程提供实时调整。

# 三、设计的模型
- 传统的基于深度学习的检测器通常表现不佳，特别是在尾部类别上，由于其固有的特征，存在长尾检测数据集(在第III-A节中)。为了解决这个问题，我们提出了一个解耦的训练框架BACL，如图2所示，其目的是在表示学习阶段(III-B)获得一个广义的特征表示，并在分类器学习阶段(III-C、III-D和III-E)校准分类偏差。在第二阶段，为了便于校准，BACL将特征提取器的参数冻结在检测器内，并引入一对互补指标进行指导(III-C)。在这些指标的基础上，BACL集成了一种新的前景分类平衡损失(III-D)，以减轻不同前景类别之间的不平等竞争。此外，动态特征幻觉模块(III-E)是量身定制的，以使样本从尾部类别多样化。

1. Preliminary
    - 继开创性工作之后，我们采用了流行的两阶段目标检测器Faster R-CNN来实现我们提出的方法。在Faster R-CNN流水线中，骨干网随机取一张图像作为输入，生成相应的feature map。RPN对特征映射进行卷积，产生固定数量的区域建议。接下来，RoIAlign层首先根据特征映射将这些区域建议池为固定大小，然后由两个完全连接(FC)层组成的RoI特征提取器将它们编码为 $d$ 维RoI特征 $\mathbf{h}$。最后，这些RoI特征被馈给两个单独的FC层，用于分类和回归。在分类分支中，网络的任务是应用 $z=FC_ {cls}(\mathbf{h})$ 解决一个 $(C + 1)$ 类预测问题( $C$ 个前景类和 $C$ 个背景类)，其中 $z = [z_ {1}, \cdots ,z_ {C+1}]$ 表示预测对数。
    - 传统的分类分支是由训练过程中的softmax交叉熵损失来监督的。对于标记为 $i$ 的提案，每个类别 $j$ 的损失通过的梯度表示为: $$\begin{equation} \frac{\partial L_ {cls}}{\partial z_ {j}} = \begin{cases} p_ {j}-1, & j=i \\ p_ {j} ,& j \neq i \\ \end{cases} \end{equation}$$ 在长尾情况下，当类别 $i$ 和 $j$ 分别属于头类和尾类时，类别 $j$ 从类别 $i$ 获得了压倒性的抑制梯度，[21]，[25]证明了这一点。因此，即使提出了积极的建议，分类器也经常给尾部类别 $j$ 分配低概率，导致分类精度较低
    - 为了提高分类精度，以往的研究[21]-[23]采用了基于sigmoid的分类器，该分类器在大词汇量数据集中表现出优越性。EQLv2引入了一个额外的对象分支来减少误报，将所有属于背景的建议视为阳性样本。在数学上，具有logits $z = [z_ {1}, \cdots ,z_ {C+1}]$ 和一个热标签 $y＝[y_ {1}, \cdots ,y_ {C+1}]$ 的训练样本的分类损失公式如下： $$\begin{equation} L_ {cls}=-\sum^{C+1}_ {i=1}log(\hat{p_ {i}}) \end{equation}$$ 其中 $$\begin{equation} \hat{p_ {i}} = \begin{cases} p_ {i}, & y_ {i}=1 \\ 1-p_ {i} ,& y_ {i}=0 \\ \end{cases} \end{equation}$$ $$\begin{equation} p_ {i} = \frac{1}{1+exp(-z_ {i})} \end{equation}$$ 在推理阶段，基于 $(C +1)$ 通道的sigmoid分类器的估计概率向量 $\tilde{\mathbf{p}} =[\tilde{p}_ {1}, \tilde{p}_ {2}, \cdots ,\tilde{p}_ {C+1}]$ 可表示为: $$\begin{equation} \hat{p_ {i}} = \begin{cases} (1-p_ {C+1}) \cdot p_ {i}, & i \le i \le C \\ p_ {C+1} ,& i=C+1 \\ \end{cases} \end{equation}$$

1. Representation Learning Stage
    - BACL侧重于在表征学习阶段获得广义特征表示，为后续分类器学习阶段提供坚实的基础。为此，我们通过全面的实验和观察，改进Faster R-CNN在表征学习阶段的训练策略。每项改进的定量结果显示在表1中。为了评估，我们对超过10个IoU阈值(0.5 - 0.95)和所有类别的框预测 $AP^{b}$ 采用101点插值平均精度。
    ![BACL_Table1](./picture/BACL_Table1.png)
    1. Sigmoid-based Classifier with an Objectness Branch
        - 如[61]所示，使用重新平衡方法会意外地降低特征表示。因此，我们采用了一个基于sigmoid的分类器，该分类器带有一个对象分支，如III-A所述，并在Eq.(2)-(5)中表述，而不使用任何重新平衡技术来调整分布。
    1. Leverage the Simple Copy-Paste Augmentation
        - 人们普遍认为，数据增强方法可以通过在数据中引入额外的变化来增强特征表示。考虑到这一点，我们用简单的复制-粘贴增强策略取代了传统的多尺度训练策略，该策略能够创建更具挑战性的训练样本，从而为解耦训练提供更好的特征表示。
    1. Other Feasible Attempts
        - 通过大量的实验，我们观察到减小权重衰减系数可以略微改善表征学习。这可以归因于减少对权值的限制扩展了特征表达式的参数搜索空间，最终导致增强的表示。此外，通过将非最大抑制操作后保留的提案数量从1000个增加到2000个，我们增加了转发给后续RoI特征提取器的前景提案数量。因此，数量的增加有助于RoI特征提取器的收敛，并产生稍微改进的特征表示
1. The long-short-term indicators pair
    - 为了便于在分类器学习阶段校准分类偏差，我们引入一对互补的长期和短期指标，从两个角度反映分类器的学习状态:对前景类别的分类倾向和对每个类别的分类正确性
    - 一方面，长期指标在训练过程中应准确地捕捉前景类别之间的优势和分类器对各个前景类别的倾向，从而指导分类均衡的实现。有三种类型的统计可以满足这一需求:静态统计、一阶动态统计和二阶动态统计。每个类型都在 Tab II 中枚举，以及在假设类别 $i$ 优于类别 $j$ 的情况下确定优势类别的相应标准。
    - 首先，静态统计提供了关于数据集的先验信息，并在整个训练过程中保持不变。然而，它们不能动态跟踪分类平衡，只能提供粗略的估计。最常用的静态统计包括每个类别 $i$ 的一维图像频率 $f_ {i}$ 和实例频率 $F_ {i}$
    - 其次，一阶动态统计量在训练过程中不断更新，可以更好地了解分类平衡状态。这些统计包括累计实例数 $N_ {i}$，迭代第 $t$ 时的平均分类分数 $s^{t}_ {i}$，以及每个类别 $i$ 的在线真阳性率 $TPR_ {i}$ (见表II为具体方程)
    - 第三，二阶动态统计量，由混淆矩阵 $M \in \mathbb{R}^{C \times C}$ 表示，捕捉细粒度的类间关系。与只考虑每个类别中的分类信息的统计相比，它们提供了一种理论上优越的方法。
    - 另一方面，尽管上述长期指标在表明分类平衡方面是有效的，但它们缺乏评估正确性的能力。为了解决这一限制，我们引入了短期指标，可以评估分类结果的正确性。这些指标指导分类器专注于具有挑战性的类别，从而进一步增强辨别力。具体而言，方程（5）中预测概率向量 $\tilde{\mathbf{p}}$ 的前 $C$ 项。无缝地满足了我们的要求。因此，在这项工作中，我们将向量 $[\tilde{p}_ {1}, \tilde{p}_ {2}, \cdots , \tilde{p}_ {C}]$ 视为短期指标。
    - 综上所述，长期指标和短期指标是互补的，为监测分类器的学习状态提供了正交的视角。它们解决了以前只关注任何方面的工作的缺点，形成了我们提出的FCBL和FHM的基础
1. Formulation of Foreground Classification Balance Loss
    - 在互补指标对的基础上，我们设计了前景分类平衡损失(FCBL)来解决长尾场景中不同前景类别之间普遍存在的不平等竞争。值得注意的是，该损失函数仅适用于前景建议，而背景建议的损失仍由Eq(2)计算。这种设计允许分类器保持前景和背景之间的区分能力。形式上，FCBL可以表示为: $$\begin{equation} L_ {FCBL}=-log(p_ {i})-log(1-p_ {C+1})-\sum^{C}_ {j=1,j \neq i}w_ {j}log(1-p^{'}_ {j}) \end{equation}$$ 其中 $i$ 为每个前景方案的真值标签，$p_ {i}, p_ {C+1}$ 与式(4)一致。但$p^{'}_ {j}$由式(8)给出;定义$w_ {j}$如式(9)所示。
    - 首先，FCBL在任何一对前景类别之间引入自适应类别感知边界，以改善一个类别对另一个类别的统治。边际与相应的长期指标的比率成对数比例。例如，考虑前景类别 $i$ 的样本，$i$ 与另一个前景类别 $j$ 之间的边际 $\delta_ {ij}$ 由式(7)定义 $$\begin{equation} \delta_ {ij} = \alpha \cdot log(\frac{l_ {j}}{l_ {i}}) \end{equation}$$ 其中 $\alpha$ 控制边际范围，$\frac{l_ {j}}{l_ {i}}$ 表示长期指标的统一表达式，可以采用 $f_ {i}, F_ {i}, N_ {i}, s^{t}_ {i}, TPR_ {i}$ 或 $M_ {j,i}$ 表示 $l_ {i}$ 。
    - 然后根据式(8)重新表示每个非真值前景类别 $j$ 的概率: $$\begin{equation} p^{'}_ {j} = \frac{1}{1+exp[-(z_ {j} + \delta_ {ij})]} \end{equation}$$ 在这种形式下，自适应类感知边际 $\delta_ {ij}$ 具有以下特征: (1)如果真类 $i$ 强于类 $j$ (根据表II中的判据确定)，边际 $\delta_ {ij}$ 为负。这种抑制的减少允许分类器为类别 $j$ 分配更高的概率。(2)相反，如果条件相反， $\delta_ {ij}$ 将为正。这个正余量鼓励分类器通过更大的抑制梯度来降低强类别 $j$ 的置信度。因此，这种裕度设计使FCBL能够感知类别差异并动态调整抑制梯度的大小。
    - 其次，自然数据和长尾数据通常具有较大的词汇集，这增加了无偏倚训练分类器的难度。在ACSL的激励下，FCBL将由Eq(9)定义的自调整权项 $w_ {j}$ 纳入到每个非真前景类别 $j$ (其中 $1 \le j \le C, j \neq i$ )的二元交叉熵损失中，其中 $\tilde{p}_ {t}$ 是预定义的阈值, $\tilde{p}_ {i}$, $\tilde{p}_ {j}$ 表示相应的短期指标。 $$\begin{equation} w_ {j} = \begin{cases} 1, & \tilde{p}_ {j} \ge \tilde{p}_ {i} \\ 1, & \tilde{p}_ {j} \ge \tilde{p}_ {t} \\ 0, & otherwise \\ \end{cases} \end{equation}$$
    - 引入自动调整权重项的目的是优先考虑混淆类别，而忽略分类良好的类别，如图3所示。具体来说，学习从输出逻辑到具体类别预测的合适映射保证了错误分类类别的损失( $\tilde{p}_ {j} \ge \tilde{p}_ {i}$ )。此外，尽管一些非真实类别可能没有比实际类别更高的概率，分类器仍然在预定义的阈值上分配过高的概率( $\tilde{p}_ {j} \ge \tilde{p}_ {t}$ )。这一观察结果表明，分类器在基本真理类别和这些相似的非基本真理类别之间缺乏辨别能力。通过在反向传播过程中对这两个源的损失进行聚合，可以提高分类器的泛化能力。遗憾的是，有着类似动机的ACSL只考虑了后一种情况。
    ![BACL3](./picture/BACL3.png)

    - 最后，在推理阶段，分类器学习阶段的估计概率向量保持为 $\tilde{\mathbf{p}}=[\tilde{p}_ {1}, \tilde{p}_ {2}, \cdots ,\tilde{p}_ {C+1}]$，由Eq(5)定义。
1. Feature Hallucination Module
    - 虽然FCBL解决了前景类别之间不平等竞争的问题，但它未能解决尾部类别代表性不足的问题。例如，“诱饵”类别只有一个训练样本。训练样本的极度稀缺性阻碍了分类器对该类的识别能力。以前的大多数研究都采用了各种重新采样方法来增加尾部类别的训练样本数量。然而，样本多样性不仅突出了数量，还突出了样本之间的差异。不幸的是，以前的方法忽略了纳入额外的数据变化，从而阻碍了尾部类别的进一步改进。
    - 为了克服这个问题，我们提出了一个简单而有效的特征幻觉模块(FHM)，通过合成幻觉特征来增强特征空间中的表征，特别是尾部类别的表征，以提高数据的多样性。如图2(b)所示，FHM首先实时捕获每个类别的特征分布，然后根据长期指标提供的指导，生成所选类别的训练特征。
    - 具体而言，FHM使用非可学习的边界框生成器生成与ground-truth边界框具有大量重叠的区域建议，灵感来自[18]。与RPN相比，边界框生成器使用坐标操作将图像中的ground-truth边界框随机转换为正建议。形式上，对于一批训练图像 $I$，所设计的盒生成器将 $I$ 中每个实例的盒坐标 $b_ {GT} = [x_ {1}, y_ {1}, x_ {2}, y_ {2}]$ 作为输入，其中 $(x_ {1}, y_ {1}), (x_ {2}, y_ {2})$ 分别表示左上角和右下角的坐标。然后，它为 $I$ 中的每个实例生成16个密集建议，其位置略有偏移，如下所示: $$\begin{equation} \hat{b}=[x_ {1} + \frac{\eta_ {1}w}{6}, y_ {1} + \frac{\eta_ {2}h}{6}, x_ {2} + \frac{\eta_ {3}w}{6}, y_ {2} + \frac{\eta_ {4}h}{6}] \end{equation}$$ 其中 $\eta_ {i} \in [−1,1]$ 是randomly selected, $w, h$ 是框的宽度和高度, 即, $w = x_ {2} − x_ {1}, h = y_ {2} − y_ {1}$。显然，每个提案在前景和背景方面与其余15个提案略有不同，这有助于增加样本方差。
    - 之后，随后的RoIAlign层和RoI特征提取器将它们编码为RoI特征，不是为了分类和回归，而是为了收集在线特征分布，其中包括原型和方差。具体而言，FHM计算 $I$ 中出现的每个类别 $i$ 的特征的均值 $u_ {i}$ 和方差 $v_ {i}$ ，然后使用Eq(11)中定义的指数移动平均函数改变相应的原型 $\mu_ {i}$ 和方差 $\delta_ {i}$ 。 $$\begin{equation}\begin{aligned} \mu_ {i} & \leftarrow \beta \mu_ {i} + (1 - \beta) u_ {i} \\ \delta_ {i} & \leftarrow \beta \delta_ {i} + (1 - \beta) v_ {i} \end{aligned}\end{equation}$$
    - 最后，FHM通过为每个类别 $i$ 分配一个抽样概率 $sp_ {i}$ 来保证尾部类别的突出性，该抽样概率 $sp_ {i}$ 与长期指标 $l_ {i}$ 成反比: $$\begin{equation} sp_ {i}=\frac{1-l_ {i}}{\sum^{C}_ {k=1}(1-l_ {k})}, \quad i \in 1, \cdots C, \end{equation}$$ 其中 $l_ {i}$ 可以是 $f_ {i}, F_ {i}, N_ {i}, s^{t}_ {i}, TPR_ {i}$ 或者 $M_ {i,i}$。利用上述采样概率，FHM随机选择 $c$ 个类别，通过再参数化技巧不断更新特征分布，为每个类别 $i$ 生成 $m$ 个幻觉特征: $$\begin{equation} f_ {i}=\mu_ {i} + \epsilon \odot \delta_ {i}, \epsilon \in \mathcal{N}(0,1) \end{equation}$$
    - 因此，在长期指标的指导下，FHM通过引入新颖的幻觉特征(特别是尾部类别)来动态增强数据多样性，从而缓解代表性不足的问题。
    - 总之，算法1概述了所提出的BACL框架中分类器学习阶段的流水线。
    ![BACL_Algorithm1](./picture/BACL_Algorithm1.png)

# 四、实验结果

## 1、比之前模型的优势

## 2、有优势的原因
- 我们进行了一系列消融研究，以更好地了解BACL。所有相关实验均在LVIS v0.5上使用Faster R-CNN与ResNet-50-FPN骨干网进行
1. Effectiveness of training strategies utilized in the representation learning stage
    - Table I显示了所提出的训练策略在表征学习阶段的效果。基线模型在尾部类别上的表现令人沮丧，在罕见和常见类别上的AP分别为1.6%和15.0%。基于sigmoid的分类器略微提高了尾部类别的检测性能，但导致头部类别的AP下降了0.6%。然而，对象分支的包含在所有类别组中产生了显著的性能增益，导致总体AP为20.5%。此外，将非最大抑制后保留的提案数量增加一倍，并采用较小的权重衰减系数，进一步提高了性能，特别是对于 $AP_ {r}$ 和 $AP_ {c}$ 。通过简单的复制-粘贴增强方法和以上所有策略，最终检测器在表示学习阶段达到了21.7%的AP，大大优于基线模型。这些消融实验证实了我们所采用的表征学习训练策略的有效性。
1. Comparison of various long-term indicators
    - 在分类器学习阶段，我们对表II中列出的长期指标进行顺序评价。相应结果如图4所示。使用Tab Ⅰ的最后一行中的检查点初始化模型。总体精度为21.7%。有趣的是，一维静态统计数据和一阶动态统计数据在总体精度方面表现出相当的性能(蓝线)。这一意外的观察结果挑战了我们最初的推测和早期的研究，表明在一个精心设计的框架内，这两种类型的统计数据可以产生类似的影响。此外，混淆矩阵和真阳性率显示出最高的整体表现，分别排名第一和第二。值得注意的是，当用作长期指标时，罕见（橙色线）和频繁（黄色线）类别的真实阳性率都达到了最高的精度。然而，在APc（灰线）方面，混淆矩阵与其他统计数据之间的巨大差距确立了前者优越的整体性能。因此，我们得出结论，在处理长尾分布时，对类间关系进行建模有利于去偏。此后，所有实验都采用混淆矩阵作为长期指标。
    ![BACL4](./picture/BACL4.png)
1. Component Analysis
    - 如第III-D节和III-E节所述，BACL集成了三个组件来校准分类器学习阶段的分类偏差：自适应类感知裕度，自动调整权重项和动态特征幻觉模块。对这些成分的不同组合进行了一系列实验，结果记录在Tab Ⅲ
    ![BACL_Table3](./picture/BACL_Table3.png)

    - 最初的发现(前四行)展示了每个组件在提高检测器在长尾数据上的性能方面的单个有效性。具体来说，类别感知边际分别将 $AP_ {r}$ 和 $AP_ {c}$ 提高了4.7%和3.5%，而不会影响频繁类别的性能。同样，自动调整的权重项也会产生类似的结果。然而，权重项略微提高了头部类别的辨别能力，而与边际相比，它对尾部类别的影响不太显著。与基线模型相比，FCBL提高了每个类别组的性能，并将总体精度提高了2.2%。这一改进验证了FCBL有效地减少了前景不平衡类别之间的误分类
    - 此外，FHM在LVIS v0.5上使用ResNet-50-FPN主干实现了26.5%的AP，比基线模型高出4.5%的AP。这一结果甚至超过了大多数最先进的方法，如表13所示。值得注意的是，该模块专为多样化样本而设计，尤其是尾部类别的样本，使 $AP- {r}$（罕见类别为+13.9%AP）和 $AP_ {c}$（常见类别为+5.5%AP）显著提高。更令人惊讶的是，FHM在头部类别中获得了与基线模型相当的性能，分别为29.8%和30.1%的AP。这一发现强调了增加样本多样性在解决长尾问题中的关键作用。
    - 最后，通过合并所有三个组件，BACL实现了令人印象深刻的27.8%的AP，优于任何其他组合。BACL在 $AP_ {r}$ 和 $AP_ {c}$ 上的AP分别为20.1%和28.2%，显著促进了各阶层之间的平衡。
    ![BACL_Table13](./picture/BACL_Table13.png)
1. Hyper-parameters
    - 我们进行了一组全面的实验，以检查不同成分中超参数的影响，即 $\alpha, \tilde{p}_ {t}, \beta, c, m$ 。表IV提出了 $\alpha$ 对控制幅度的类意识裕度的影响的研究。当 $\alpha$ 设为0时，去除自适应余量，整体性能最低，为27.2% AP。 $\alpha$ 的最优值为0.85，其中 $AP^{b}$ 、$AP_ {c}$ 和 $AP_ {f}$ 均达到峰值。如果偏离这个最优值，在罕见类别上的性能会进一步提高，但代价是在常见和频繁类别上的性能会略有下降。因此，我们将 $\alpha$ 设为0.85以达到最佳折衷。
    ![BACL_Table4](./picture/BACL_Table4.png)

    - 在表V，我们改变FCBL中使用的概率阈值 $\tilde{p}_ {t}$，发现获得的最佳结果为0.7。偏离这个阈值会导致整体性能下降。接下来，我们研究了 $\beta$ 的影响，它决定了FHM中特征分布的更新速度。表VI说明了给以前的特性分配过多的权重会显著影响整体性能。因此，我们选择0.9的值以获得更好的性能。关于采样类别的数量和合成的幻觉特征，表VII表示最优设置为 $c = 8, m = 12$
    ![BACL_Table5678](./picture/BACL_Table5678.png)
1. Formulation of the confusion matrix
    - 与软标签相对于一热硬标签的优势类似，表Ⅱ中混淆矩阵的计算公式优于其传统定义: $$\begin{equation} M_ {i,j}=\frac{\sum_ {n} Ⅱ [\underset{k}{argmax}p_ {n,k}=j] \cdot Ⅱ [y_ {n,i}=1]}{\sum_ {n} Ⅱ [y_ {n,i}=1]}, 1 \le i,j \le C \end{equation}$$ 原因在于前者考虑的是分类器感知到的不同类别之间的相关性，而Eq(14)只关注分类正确性。因此，前者为校准提供了更多的指导性信息，如表8所示
1. Formulation of the weight term
    - 在等式(9)中，我们计算了错误分类的类别以及过度自信的非基本事实类别的损失。为了获得进一步的见解，我们一次只考虑一个方面来进行额外的实验。表IX中给出的结果阐明了错误分类类别损失对检测器的重要性。当排除这些损失时，尽管AP略有改善，但该模型仅实现了20.1%的总体AP。此外，惩罚过于自信的非地面实况类会适度提高0.3%的性能
1. Training pipelines
    - 我们用端到端培训管道来评估BACL，但结果令人失望，只有22.0%的AP，如表X所示。原因可能是未冻结的特征提取器会对每个类别的原型产生不利影响，阻止FHM合成歧视性的幻觉特征。
1. Whether the classifier is balanced?
    - 如以往文献[16]所示，分类器的权值范数与其对应类别的分类精度密切相关。因此，我们在图5中可视化了通过基线、EQLv2和BACL三种方法训练的各种分类器的权重规范。显然，基线模型的权重范数与每个类别的训练实例数量呈正相关，从而解释了尾部类别的表现不佳。虽然EQLv2增加了所有类别的权重规范，但它仍然存在明显的权重规范不平衡。相反，BACL极大地改善了每个类别的权重规范不平衡，并绘制了一条近乎水平线，这解释了它在所有类别之间的平衡性能。
1. FLOPs, Params and FPS
    - 我们在表XI中提供了基线模型和BACL之间的浮点运算（FLOP）、参数（Params）和每秒帧数（FPS）的比较。由于BACL仅依赖于分类器统计来进行去偏，并且不引入任何可训练的参数，因此BACL的参数和FLOP的数量与基线模型的数量和FLOP保持相同。然而，基线模型的FPS几乎是BACL的三倍。这可以基于这样的观察来解释，即BACL监督的分类器为提案分配更高的分数，导致非最大值抑制处理的提案数量是前者的三倍。由于非最大值抑制在CPU上运行，所需时间与正在处理的提案数量成比例。

## 3、改进空间

# 五、结论
- 本文提出了一种统一的长尾目标检测框架BACL。BACL采用分而治之的方法，引入FCBL来缓解前景类别之间的不平等竞争，引入FHM来增强尾部类别的多样性。大量的实验表明，BACL为检测器提供了跨各种主干和体系结构的更平衡和准确的分类分支。然而，BACL是在解耦训练管道的基础上设计的，限制了特征提取器在分类器学习阶段的改进。未来的工作可能会弥补这一缺陷，并整合更先进的指标和方法来添加样本方差，以进一步改进。我们相信，经过特定任务的修改后，所提出的BACL也可以应用于其他长尾识别任务。
## 1、模型是否解决了目标问题

## 2、模型是否遗留了问题

## 3、模型是否引入了新的问题

# 六、代码

# 读者角度（挖掘文章中没有提到的）：
1. 总结文章发现问题的思路
2. 总结文章改进的思想
3. 总结文章还存在或者可以改进的问题
4. 提出对模型参数和细节的一些思考和讨论