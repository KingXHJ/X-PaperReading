# 论文信息
- 时间：2015
- 期刊：CVPR
- 网络/算法名称：Faster R-CNN
- 意义：实现⼏乎⽆成本的区域提议
- 作者：Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun
- 实验环境：
- 数据集：
# 一、解决的问题
1. SPPnet 和 Fast R-CNN 等进步减少了这些检测⽹络的运⾏时间，暴露了区域提案计算的瓶颈。在这项⼯作中，我们引⼊了⼀个区域提议⽹络 (RPN)，它与检测⽹络共享全图像卷积特征，从⽽实现⼏乎⽆成本的区域提议。 RPN 是⼀种全卷积⽹络，可同时预测每个位置的对象边界和对象性分数。 RPN 经过端到端的训练以⽣成⾼质量的区域建议，Fast R-CNN 使⽤这些区域建议进⾏检测。我们通过共享 RPN 和 Fast R-CNN 的卷积特征进⼀步将 RPN 和 Fast R-CNN 合并到⼀个⽹络中
2. ⽬标检测的最新进展是由区域建议⽅法（例如 [Selective Search for Object Recognition](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf)）和基于区域的卷积神经⽹络 (R-CNN) 的成功推动的。尽管基于区域的 CNN 最初在R-CNN中开发时计算量很⼤，但由于在提议SPPnet、Fast R-CNN 之间共享卷积，它们的成本已⼤⼤降低。最新的化⾝，Fast R-CNN在忽略区域提议上花费的时间时，使⽤⾮常深的⽹络VGG实现了接近实时的速率。现在，提案是最先进的检测系统中测试时间的计算瓶颈。
3. 区域提议⽅法通常依赖于廉价的特征和经济的推理⽅案。
    - [选择性搜索]((http://www.huppelen.nl/publications/selectiveSearchDraft.pdf))是最流⾏的⽅法之⼀，它基于⼯程化的低级特征贪婪地合并超像素。然⽽，与⾼效检测⽹络Fast R-CNN相⽐，选择性搜索要慢⼀个数量级，在 CPU 实现中每张图像需要 2 秒。 [EdgeBoxes](http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/ECCV_2014/papers/8693/86930391.pdf)⽬前在建议质量和速度之间提供最佳权衡，每张图像 0.2 秒。尽管如此，区域提议步骤仍然消耗与检测⽹络⼀样多的运⾏时间。
    
    - ⼈们可能会注意到，快速的基于区域的 CNN 利⽤了 GPU，⽽研究中使⽤的区域提议⽅法是在 CPU 上实现的，这使得这种运⾏时⽐较变得不公平。加速提案计算的⼀个明显⽅法是为 GPU 重新实现它。这可能是⼀个有效的⼯程解决⽅案，但重新实现忽略了下游检测⽹络，因此错过了共享计算的重要机会。
 
# 二、做出的创新
1. 在本⽂中，我们展⽰了⼀种算法变化。使⽤深度卷积神经⽹络计算提案。导致了⼀个优雅⽽有效的解决⽅案，其中提案计算⼏乎没有成本给检测⽹络的计算。为此，我们引⼊了新的区域提议⽹络 (RPN)，它与最先进的⽬标检测⽹络 SPPnet、Fast R-CNN 共享卷积层。通过在测试时共享卷积，计算建议的边际成本很⼩（例如，每张图像 10 毫秒）。
    - 我们的观察是，基于区域的检测器（如 Fast R CNN）使⽤的卷积特征图也可⽤于⽣成区域建议。在这些卷积特征之上，我们通过添加⼀些额外的卷积层来构造⼀个 RPN，这些卷积层同时回归规则⽹格上每个位置的区域边界和对象得分。因此，RPN 是⼀种[完全卷积⽹络 (FCN)](https://www.semanticscholar.org/reader/317aee7fc081f2b137a85c4f20129007fd8e717e)，可以专⻔针对⽣成检测建议的任务进⾏端到端训练。
    - RPN 旨在有效地预测具有⼴泛尺度和纵横⽐的区域提案。图像⾦字塔（图 1，a）或过滤器⾦字塔（图 1，b），我们引⼊了新颖的“锚定”框，可在多个尺度和纵横⽐下⽤作参考。我们的⽅案可以被认为是回归参考⾦字塔（图 1，c），它避免枚举图像或多个尺度或纵横⽐的过滤器。该模型在使⽤单尺度图像进⾏训练和测试时表现良好，因此有利于运⾏速度。
        ![Faster R-CNN1.png](../pictures/Faster%20R-CNN1.png)

    - 为了将 RPN 与 Fast R-CNN 对象检测⽹络统⼀起来，我们提出了⼀种训练⽅案，该⽅案在区域建议任务微调和对象检测微调之间交替进⾏，同时保持建议固定。该⽅案可以快速收敛并⽣成⼀个统⼀的⽹络，该⽹络具有两个任务之间共享的卷积特征。我们在 PASCAL VOC 检测基准上全⾯评估了我们的⽅法，其中具有 Fast R-CNN 的 RPN 产⽣的检测精度优于强使⽤ Fast R-CNN 进⾏选择性搜索的基线。同时，我们的⽅法在测试时⼏乎消除了选择性搜索的所有计算负担

2. 相关工作
    1. 对象提案。有⼤量关于对象提议⽅法的⽂献。在[How good are detection proposals, really?](https://arxiv.org/pdf/1406.6962.pdf)、[What makes for effective detection proposals?](https://www.semanticscholar.org/reader/6c016579af5becc230fb9efc1f885f2afa65a46e)、[Object-Proposal Evaluation Protocol is ‘Gameable’](https://arxiv.org/pdf/1505.05836.pdf)中可以找到对象提议⽅法的综合调查和⽐较。⼴泛使⽤的对象提议⽅法包括基于超像素分组的⽅法（例如，[Selective Search for Object Recognition](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf)、[CPMC](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6095566)、[MCG](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/papers/apbmm_cvpr2014.pdf)）和基于滑动窗⼝的⽅法(例如，[objectness in windows](https://www.pure.ed.ac.uk/ws/files/17686204/Alexe_et_al_2010_Measuring_the_objectnessi.pdf)、[EdgeBoxes](http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/ECCV_2014/papers/8693/86930391.pdf)).对象提议⽅法被⽤作独⽴于检测器的外部模块（例如，[选择性搜索](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf)、[CPMC](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6095566)对象检测器、R-CNN 和 Fast R-CNN ）。
    1. ⽤于对象检测的深度⽹络。 R-CNN ⽅法端到端地训练 CNN 以将提议区域分类为对象类别或背景。R-CNN主要起到分类器的作⽤，它不预测对象边界（除了通过边界框回归进⾏细化）。它的准确性取决于区域建议模块的性能。在 OverFeat ⽅法中，训练了⼀个全连接层来预测假定单个对象的定位任务的框坐标。然后转全连接层进⼊⼀个卷积层，⽤于检测多个类别的特定对象。 MultiBox ⽅法从⼀个⽹络⽣成区域建议，该⽹络的最后⼀个全连接层同时预测多个类不可知框，概括了 OverFeat 的“单框”⽅式。这些与类⽆关的框被⽤作 R-CNN 的建议。 MultiBox 建议⽹络应⽤于单个图像裁剪或多个⼤图像裁剪（例如，224×224），这与我们的全卷积⽅案形成对⽐。 MultiBox 不在提议⽹络和检测⽹络之间共享特征。我们稍后将在我们的⽅法的上下⽂中更深⼊地讨论 OverFeat 和 MultiBox。在我们⼯作的同时，DeepMask ⽅法被开发⽤于学习分割建议。
    1. 卷积的共享计算已经吸引了越来越多的关注，以实现⾼效但准确的视觉识别。 OverFeat 论⽂从图像⾦字塔计算卷积特征以进⾏分类、定位和检测。共享卷积特征图上的⾃适应⼤⼩池化 (SPP)是为⾼效的基于区域的对象检测和语义分割⽽开发的。 Fast R-CNN⽀持对共享卷积特征进⾏端到端检测器训练，并显⽰出令⼈信服的准确性和速度。

# 三、设计的模型
- 我们的⽬标检测系统称为 Faster R-CNN，由两个模块组成。第⼀个模块是提出区域的深度全卷积⽹络，第⼆个模块是使⽤提出区域的 Fast R-CNN 检测器。整个系统是⼀个⽤于对象检测的单个统⼀⽹络（图 2）。使⽤最近流⾏的具有[“注意”](https://www.semanticscholar.org/reader/b624504240fa52ab76167acfe3156150ca01cf3b)机制的神经⽹络术语，RPN 模块告诉 Fast R-CNN 模块去哪⾥看。
    ![Faster R-CNN2.png](../pictures/Faster%20R-CNN2.png)

1. Region Proposal Networks(RPN网络)
    - 像（任意⼤⼩）作为输⼊并输出⼀组矩形对象提议，每个提议都有⼀个⽬标得分。我们使⽤全卷积⽹络对这个过程进⾏建模，我们将在本节中进⾏描述。因为我们的最终⽬标是与 Fast R-CNN 对象检测⽹络共享计算，所以我们假设两个⽹络共享⼀组通⽤的卷积层。在我们的实验中，我们研究了具有 5 个可共享卷积层的 Zeiler 和 Fergus 模型[ZF](https://arxiv.org/pdf/1311.2901.pdf) 以及具有 13 个可共享卷积层的 Simonyan 和 Zisserman 模型(VGG-16)。

    - 为了⽣成区域建议，我们在最后⼀个共享卷积层输出的卷积特征图上滑动⼀个⼩型⽹络。这个⼩型⽹络将输⼊卷积特征图的 $n \times n$ 空间窗⼝作为输⼊。每个滑动窗⼝都映射到⼀个较低维度的特征（ZF 为 256-d，VGG 为 512-d，随后是 [ReLU](https://icml.cc/Conferences/2010/papers/432.pdf)）。该特征被送⼊两个同级的全连接层

    1. 锚点
        - 在每个滑动窗⼝位置，我们同时预测多个区域建议，其中每个位置的最⼤可能建议的数量表⽰为 $k$ 。因此，$reg$ 层有 $4k$ 个输出编码 $k$ 个框的坐标，$cls$ 层输出 $2k$ 个分数，⽤于估计每个 proposal 的对象或⾮对象的概率。 $k$ 个提议是相对于 $k$ 个参考框进⾏参数化的，我们称之为锚。锚点位于所讨论的滑动窗⼝的中⼼，并与⽐例和纵横⽐相关联（图 3，左）。默认情况下，我们使⽤ 3 个尺度和 3 个纵横⽐，在每个滑动位置产⽣ $k = 9$ 个锚点。对于⼤⼩为 $W \times H$（通常为 2,400）的卷积特征图，总共有 $WHk$ 个锚点。
            ![Faster R-CNN3.png](../pictures/Faster%20R-CNN3.png)

        1. Translation-Invariant Anchors
            - 我们⽅法的⼀个重要特性是它是平移不变的，⽆论是在锚点还是计算相对于锚点的提案的函数⽅⾯。如果⼀个⼈翻译图像中的对象，建议应该翻译并且相同的功能应该能够在任⼀位置预测建议。这个平移不变的属性由我们的⽅法保证。作为⽐较，MultiBox ⽅法使⽤ k-means ⽣成 800 个锚点，这些锚点不是平移不变的。所以 MultiBox 不保证如果翻译了⼀个对象，就会⽣成相同的提议。
            - 平移不变属性还减⼩了模型⼤⼩。 MultiBox 有⼀个 $(4 + 1) \times 800$ 维的全连接输出层，⽽我们的⽅法在 $k = 9$ 锚点的情况下有⼀个 $(4 + 2) \times 9$ 维的卷积输出层。因此，我们的输出层有 $2.8 \times 104$ 个参数 $(VGG-16 为 512 \times (4 + 2) \times 9)$ ，⽐ MultiBox 的输出层有 $6.1 \times 10^{6}$ 个参数 $(1536 \times (4 + 1 ) \times 800  for GoogleNet  in MultiBox )$ .如果考虑特征投影层，我们的建议层的参数仍然⽐ MultiBox 少⼀个数量级。我们希望我们的⽅法在⼩型数据集（如 PASCAL VOC）上过度拟合的⻛险较⼩。

        1. Multi-Scale Anchors as Regression References
            - 我们的锚点设计提出了⼀种解决多尺度（和纵横⽐）的新⽅案。如图 1 所⽰，多尺度预测有两种流⾏的⽅法。第⼀种⽅法是基于图像/特征⾦字塔，例如，在 DPM 和基于 CNN 的⽅法中。图像在多个尺度上调整⼤⼩，并为每个尺度计算特征图（HOG 或深度卷积特征）（图 1(a)）。这种⽅式经常有⽤，但很费时。第⼆种⽅法是在特征图上使⽤多个尺度（和/或纵横⽐）的滑动窗⼝。例如，在 DPM 中，不同宽⾼⽐的模型使⽤不同的过滤器尺⼨（例如 5×7 和 7×5）分别进⾏训练。如果这种⽅式⽤于解决多个尺度，它可以被认为是⼀个“过滤器⾦字塔”（图 1（b））。第⼆种⽅式通常与第⼀种⽅式联合采⽤。
            - 作为⽐较，我们的基于锚点的⽅法建⽴在锚点⾦字塔之上，更具成本效益。我们的⽅法参考多个尺度和纵横⽐的锚框对边界框进⾏分类和回归。它仅依赖单⼀尺度的图像和特征图，并使⽤单⼀尺⼨的过滤器（特征图上的滑动窗⼝）。我们通过实验展⽰了该⽅案对解决多个尺度和⼤⼩的影响（表 8）。
                ![Faster R-CNN Table8.png](../pictures/Faster%20R-CNN%20Table8.png)
            
            - 由于这种基于锚点的多尺度设计，我们可以简单地使⽤在单尺度图像上计算的卷积特征，就像 Fast R-CNN 检测器所做的那样。多尺度锚点的设计是共享特征的关键组成部分，⽆需额外成本来解决尺度问题。
    
    2. 损失函数
        - 为了训练 RPN，我们为每个锚点分配⼀个⼆进制类标签（是否为对象）。我们为两种锚标记正标签：（i）具有最⾼交叉联合（IoU）的锚/锚与真值框重叠，或（ii）IoU重叠⾼于0.7 与任何真值框。请注意，单个真值框可能会将正标签分配给多个锚点。通常第⼆个条件⾜以确定正样本；但我们仍然采⽤第⼀个条件，因为在极少数情况下第⼆个条件可能找不到正样本。如果所有真实框的 IoU ⽐率低于 0.3，我们将负标签分配给⾮正锚。既不是正⾯也不是负⾯的锚点对训练⽬标没有贡献。
        - 通过这些定义，我们最⼩化了 Fast R-CNN 中多任务损失后的⽬标函数。我们对图像的损失函数定义为：
            $$\begin{align}
            L({p_ {i}},{t_ {i}}) &= \frac{1}{N_ {cls}} \sum_ {i}L_ {cls}(p_ {i},p^{*}_ {i}) \notag\ \\
                                 &+ \lambda \frac{1}{N_ {reg}} \sum_ {i} p^{*}_ {i} L_ {reg}(t_ {i},t^{*}_ {i})
            \end{align}$$
            这里， $i$ 是小批量中锚点的索引， $p_ {i}$ 是锚点 $i$ 作为对象的预测概率。如果锚点为正，则地面真实标签 $p^{*}_ {i}$ 为 $1$ ，如果锚点为负，则为0。 $t_ {i}$ 是表示预测边界框的4个参数化坐标的向量， $t^{*}_ {i}$ 是与正锚相关联的地面真实框的坐标。分类损失 $L_ {cls}$ 是两类（对象与非对象）的日志损失。对于回归损失，我们使用 $L_ {reg}(t_ {i}, t^{*}_ {i})$ ，其中 $R$ 是中定义的鲁棒损失函数（平滑 $L_ {1}$ ）。术语 $p^{*}_ {i}L_ {reg}$ 表示回归损失仅对正锚点（ $p^{*}_ {i} = 1$ ）激活，否则禁用（ $p^{*}_ {i} = 0$ ）。 $cls$ 和 $reg$ 层的输出分别由 $\{ p_ {i} \}$ 和 $\{ t_ {i} \}$ 组成

        - 这两项由 $N_ {cls}$ 和 $N_ {reg}$ 归一化，并由平衡参数 $\lambda$ 加权。在我们当前的实现中（如在发布的代码中）公式（1）的 $cls$ 项，通过小批量大小（即 $N_ {cls}＝256$）归一化，并且通过锚定位置的数量（即 $N_ {reg}～2400$ ）归一化 $reg$ 项。默认情况下，我们将 $\lambda$ 设置为10，因此 $cls$ 和 $reg$ 项的权重大致相等。我们通过实验表明，结果在宽范围内对 $\lambda$ 值不敏感（表9）。我们还注意到，上述规范化不是必需的，可以简化。
            ![Faster R-CNN Table9.png](../pictures/Faster%20R-CNN%20Table9.png)
        
        - 对于边界框回归，我们采⽤参数R-CNN之后的 4 个坐标的 eterizations：
            $$\begin{align}
            t_ {x} = (x - x_ {a}) / w_ {a}, &   &t_ {y} = (y - y_ {a}) / h_ {a},
            t_ {w} = log(w / w_ {a}), &   &t_ {h} = log(h / h_ {a}),
            t^{*}_ {x} = (x^{*} - x_ {a}) / w_ {a}, &   &t^{*}_ {y} = (y^{*} - y_ {a}) / h_ {a},
            t^{*}_ {w} = log(w^{*} / w_ {a}), &   &t^{*}_ {h} = log(h^{*} / h_ {a}),
            \end{align}$$
            其中 $x、y、w和h$ 表示长方体的中心坐标及其宽度和高度。变量 $x、xa和x*$ 分别用于预测框、锚框和真值框（同样适用于 $y、w、h$ ）。这个可以被认为是从锚框到附近的真实框的边界框回归。

        - 尽管如此，我们的⽅法通过与以前基于 RoI（感兴趣区域）的⽅法 SPPnet、Fast R-CNN 不同的⽅式实现边界框回归。在 SPPnet、Fast R-CNN 中，对从任意⼤⼩的 RoI 汇集的特征执⾏边界框回归，并且回归权重由所有区域⼤⼩共享。在我们的公式中，⽤于回归的特征在特征图上具有相同的空间⼤⼩（ $3×3$ ）。为了考虑到不同的⼤⼩，学习了⼀组 $k$ 个边界框回归器。每个回归器负责⼀种尺度和⼀种纵横⽐，$k$ 个回归器不共享权重。因此，由于锚点的设计，即使特征具有固定⼤⼩/⽐例，仍然可以预测各种⼤⼩的框。

    3. 训练 RPNs
        - RPN 可以通过反向传播和随机梯度下降（SGD）进⾏端到端的训练。我们遵循 Fast R-CNN 中的“以图像为中⼼”的采样策略来训练该⽹络。每个⼩批量都来⾃包含许多正⾯和负⾯⽰例锚点的单个图像。可以优化所有锚点的损失函数，但这会偏向负样本，因为它们占主导地位。相反，我们在⼀张图像中随机采样 256 个 anchors 来计算 mini-batch 的损失函数，其中采样的正负 anchors 的⽐例⾼达 1:1。如果图像中的正样本少于 128 个，我们会⽤负样本填充⼩批量。

        - 我们通过从标准差为 0.01 的零均值⾼斯分布中抽取权重来随机初始化所有新层。所有其他层（即共享卷积层）都通过预训练 ImageNet 分类模型 进⾏初始化，这是标准做法R-CNN。我们调整 ZF ⽹络的所有层，以及 VGG ⽹络的 conv3 1 和更⾼层以节省内存 Fast R-CNN。我们在 PASCAL VOC 数据集上对 60k ⼩批量使⽤ 0.001 的学习率，对接下来的 20k ⼩批量使⽤ 0.0001。我们使⽤ 0.9 的动量和 0.0005 的权重衰减。我们的实现使⽤ Caffe。

2. RPN 和 Fast R-CNN 的共享特征
    - 到⽬前为⽌，我们已经描述了如何训练⼀个⽹络来⽣成区域提议，⽽没有考虑将利⽤这些提议的基于区域的⽬标检测 CNN。对于检测⽹络，我们采⽤ Fast R-CNN 。接下来，我们将描述学习由 RPN 和具有共享卷积层的 Fast R-CNN 组成的统⼀⽹络的算法（图 2）。
    
    - 独立训练的RPN和Fast R-CNN都将以不同的方式修改其卷积层。因此，我们需要开发一种技术，允许在两个网络之间共享卷积层，而不是学习两个独立的网络。我们讨论了三种具有共享功能的培训网络方式：
        1. 交替训练。在这个解决⽅案中，我们⾸先训练 RPN，然后使⽤建议来训练 Fast R-CNN。然后⽤Fast R-CNN调优的⽹络初始化RPN，迭代这个过程。这是本⽂所有实验中使⽤的解决⽅案。

        2. 近似联合训练。在此解决⽅案中，RPN 和 Fast R-CNN ⽹络在训练期间合并为⼀个⽹络，如图 2 所⽰。在每次 SGD 迭代中，前向传递⽣成区域提议，在训练快速 R-CNN 检测器。反向传播像往常⼀样发⽣，对于共享层，来⾃ RPN 损失和 Fast R-CNN 损失的反向传播信号被组合。该解决⽅案易于实施。但是这个解决⽅案忽略了建议框坐标的导数，它也是⽹络响应，所以是近似的。在我们的实验中，我们凭经验发现这个求解器产⽣了接近的结果，但与交替训练相⽐，训练时间减少了⼤约 25-50%。这个求解器包含在我们发布的 Python 代码中。

        3. ⾮近似联合训练。如上所述，RPN 预测的边界框也是输⼊的函数。 Fast R-CNN 中的 RoI 池化层接受卷积特征以及预测的边界框作为输⼊，因此理论上有效的反向传播求解器还应该涉及框坐标的梯度。在上述近似联合训练中忽略了这些梯度。在⾮近似联合训练解决⽅案中，我们需要⼀个可微分 wrt 框坐标的 RoI 池化层。这是⼀个⾮常重要的问题，可以通过 [Instance-aware Semantic Segmentation via Multi-task Network Cascades](https://www.semanticscholar.org/reader/1e9b1f6061ef779e3ad0819c2832a29168eaeb9d) 中开发的“RoI warping”层给出解决⽅案，这超出了本⽂的范围。

    - 4步交替训练。在本⽂中，我们采⽤实⽤的 4 步训练算法通过交替优化来学习共享特征。
        1. 在第⼀步中，我们按照第 3.1.3 节中的描述训练 RPN。该⽹络使⽤ ImageNet 预训练模型进⾏初始化，并针对区域提案任务进⾏端到端微调。

        2. 在第⼆步中，我们使⽤步骤 1 RPN ⽣成的建议通过 Fast R-CNN 训练⼀个单独的检测⽹络。该检测⽹络也由 ImageNet 预训练模型初始化。此时两个⽹络不共享卷积层。

        3. 第三步，我们使⽤检测器⽹络初始化RPN训练，但是我们修复共享的卷积层，只微调 RPN 特有的层。现在两个⽹络共享卷积层。最后，在保持共享卷积层不变的情况下，我们微调了 Fast R-CNN 的独特层。因此，两个⽹络共享相同的卷积层并形成⼀个统⼀的⽹络。类似的交替训练可以运⾏更多次迭代，但我们观察到的改进微乎其微。

3. 实现细节
    - 我们在单⼀尺度的图像上训练和测试区域提议和⽬标检测⽹络SPPnet，Fast R-CNN。我们重新缩放图像，使它们的短边为 s = 600 像素。多尺度特征提取（使⽤图像⾦字塔）可能会提⾼准确性，但不会表现出良好的速度-准确性权衡。在重新缩放的图像上，ZF 和 VGG ⽹络在最后⼀个卷积层上的总步幅为 16 个像素，因此在调整⼤⼩（~500×375）之前的典型 PASCAL 图像上为 ~10 个像素。即使是这样⼤的步幅也能提供良好的结果，但更⼩的步幅可能会进⼀步提⾼准确性。
    
    - 对于锚点，我们使⽤ 3 个尺度，盒⼦⾯积为 $128^{2},256^{2}和 512^{2}$ 像素，以及 1:1、1:2 和 2:1 的 3 种纵横⽐。这些超参数并不是针对特定数据集精⼼选择的，我们在下⼀节中提供了关于它们效果的消融实验。正如所讨论的，我们的解决⽅案不需要图像⾦字塔或过滤器⾦字塔来预测多个尺度的区域，从⽽节省了⼤量的运⾏时间。图 3（右）显⽰了我们的⽅法适⽤于各种⽐例和纵横⽐的能⼒。表 1 显⽰了使⽤ ZF ⽹络为每个锚点学习的平均提议⼤⼩。我们注意到，我们的算法允许进⾏⽐底层感受野更⼤的预测。这样的预测并⾮不可能——如果只有物体的中间是可⻅的，⼈们仍然可以粗略地推断出物体的范围。

    - 需要⼩⼼处理跨越图像边界的锚框。在训练期间，我们忽略所有跨界锚点，因此它们不会增加损失。对于典型的 $1000 \times 600$ 图像，总共将有⼤约 $20000（\approx 60 \times 40 \times 9）$ 个锚点。在忽略跨边界锚点的情况下，每张图像⼤约有 6000 个锚点⽤于训练。如果在训练中不忽略边界交叉异常值，它们会在⽬标中引⼊⼤量难以纠正的错误项，并且训练不会收敛。然⽽，在测试期间，我们仍然将完全卷积 RPN 应⽤于整个图像。这可能会⽣成跨边界建议框，我们将其剪裁到图像边界。

    - ⼀些 RPN 提案彼此⾼度重叠。为了减少冗余，我们根据建议区域的 $cls$ 分数对建议区域采⽤⾮最⼤抑制 (NMS)。我们将 NMS 的 IoU 阈值固定为 0.7，这使得每张图像⼤约有 2000 个建议区域。正如我们将展⽰的那样，NMS 不会损害最终的检测精度，但会⼤⼤减少提议的数量。在 NMS 之后，我们使⽤排名前 N 的建议区域进⾏检测。在下⽂中，我们使⽤ 2000 个 RPN pro posals 训练 Fast R-CNN，但在测试时评估不同数量的 proposals。


# 四、实验结果

## 1、比之前模型的优势

## 2、有优势的原因

## 3、改进空间

# 五、结论

## 1、模型是否解决了目标问题

## 2、模型是否遗留了问题

## 3、模型是否引入了新的问题

# 六、代码

# 读者角度（挖掘文章中没有提到的）：
1. 总结文章发现问题的思路
2. 总结文章改进的思想
3. 总结文章还存在或者可以改进的问题
4. 提出对模型参数和细节的一些思考和讨论