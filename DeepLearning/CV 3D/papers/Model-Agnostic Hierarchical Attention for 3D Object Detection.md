# 论文信息
- 时间：2023
- 期刊：CVPR
- 网络/算法名称：
- 意义：点云网络，Transformers + "多尺度"/"尺寸自适应局部"注意力机制，实现更好的小目标的3D目标检测
- 作者：Manli Shu1*, Le Xue2, Ning Yu2, Roberto Martín-Martín2,3, Juan Carlos Niebles2, Caiming Xiong2, Ran Xu2; 1 University of Maryland; 2 Salesforce Research; 3 UT Austin
- 实验环境：
- 数据集：ScanNetV2； SUN RGB-D
# 一、解决的问题
![Model-Agnostic Hierarchical Attention for 3D Object Detection figure1](../pictures/Model-Agnostic%20Hierarchical%20Attention%20for%203D%20Object%20Detection%20figure1.png)

1. 现在的方法：Transformer作为多功能网络架构，最近在3D点云对象检测方面取得了巨大成功

2. 优势：Transformer的注意⼒机制可以建模远程关系，有助于捕获点云学习的全局上下⽂

3. 问题：然而，普通Transformer缺乏层次结构，使得难以在不同尺度上学习特征，并限制了其提取局部特征的能力。这种限制使得它们在 ***不同大小*** 的对象上具有不平衡的性能，而在 ***较小的对象上性能较差*** 

4. 问题原因的猜测：推测在⼩物体上表现不佳可能是由于两个因素
    1. ⾸先，为了使计算可⾏，与原始点云相⽐，transformer 检测器使⽤由⼀⼩组点组成的点云特征。⼴泛下采样的点云丢失了⼏何细节，这对⼩物体的影响更⼤

    2. 其次，普通转换器（例如，Transformer、 ViT）在整个⽹络的全局范围内提取特征，不⽀持显式局部特征学习

5. 期待的结果：希望现有的点云变换器能够从分层特征学习策略中受益，该策略允许多尺度特征学习并⽀持局部特征聚合

6. 策略实施的困难：
    1. 尽管如此，考虑到点云转换器的计算强度，在整个⽹络中使⽤更⾼分辨率（即更⾼的点密度）点云特征是低效的

    2. 此外，由于点云的不规则性，将层次设计和多尺度特征集成到⽤于点云⽬标检测的转换器中并⾮易事

7. 方案的优势：我们的⽅法在这项⼯作中，我们旨在通过模块化分层设计改进基于Transformer的 3D 对象检测器。我们提出了两个注意模块，⽤于多尺度特征学习和尺⼨⾃适应局部特征聚合。我们的 ***注意⼒模块与模型⽆关*** ，可以插⼊现有的点云转换器进⾏ ***端到端训练***
    1. ⾸先提出简单多尺度注意⼒（Simple Multi-Scale Attention，MS-A）。它使⽤可学习的上采样策略从单尺度输⼊特征构建更⾼分辨率的点特征，并在注意⼒函数中使⽤这两个特征。为了减少计算和参数开销，我们将多尺度特征转换为多尺度标记，并在多头注意⼒模块中执⾏多尺度到知识点聚合

    2. 第⼆个模块是 Size-Adaptive Local Attention (Local A)，它为每个候选对象学习本地化的对象级特征。它将更⼤的注意⼒区域分配给具有更⼤边界框建议的候选对象。局部注意区域由它们相应的中间边界框提议定义

    3. 我们在两个⼴泛使⽤的室内 3D对象检测基准上评估我们的⽅法：ScanNetV2和 SUN RGB D。我们将注意⼒模块插⼊最先进的基于变压器的 3D 检测器中，并执⾏端到端训练。我们的⽅法在 ScanNetV2 上将之前的最佳结果在 mAP@0.25 中提⾼了 1% 以上，在 mAP@0.50 中提⾼了 2% 以上。此外，我们的尺⼨感知评估表明，我们在⼩物体中获得了最⼤的性能提升，mAPS 增加了 2.5%

    - 简而言之：
        1. 我们提出简单多尺度注意(MS-A) 以实现对单尺度特征的多尺度特征学习

        2. 我们提出了尺⼨⾃适应局部注意（Local-A）⽤于边界框提议中的局部特征聚合

        3. 我们在两个⼴泛使⽤的室内3D检测基准上进⾏了实验，并且在两个基准上都超过了之前的最佳结果

8. 改进：在这项工作中，我们提出了两种新的注意力机制，作为基于Transformer的3D检测器的模块化分层设计。为了实现 **不同尺度** 的特征学习，我们提出了 ***简单多尺度注意*** ，该注意从单个尺度输入特征构建多尺度标记。对于 **局部特征聚合** ，我们为每个边界框提议提出了 ***具有自适应注意力范围大小的自适应局部注意力*** 。我们的两个关注模块都是模型无关的网络层，可以插入到现有的点云转换器中进行端到端培训。我们在两个广泛使用的室内3D点云对象检测基准上评估了我们的方法。通过将我们提出的模块插入到最先进的基于Transformer的3D检测器中，我们在两个基准上改进了以前的最佳结果，在 ***小物体上的改进幅度最大***

# 二、做出的创新
1. 点云学习的⽹络架构：基于⽹格的、基于点的和混合架构
    1. 基于⽹格
        - 基于⽹格的⽅法将不规则点云投影到⽹格状结构中，例如 3D 体素。借助⽹格状结构，现有⼯作提出了各种基于 3D 卷积的架构

    2. 基于点
        - 基于点的⽅法直接从原始点云中学习特征。在此类别中，基于图的⽅法使⽤图来模拟点之间的关系

        - 另⼀种⼯作将点云建模为⼀组点，并通过集合抽象提取特征。最近的⼯作探索了⽤于基于点的学习的转换器架构，其中每个点都作为令牌输⼊转换器，注意⼒机制在全局范围内学习点特征
    
    3. 本文工作思想：
        - 虽然以前的⽅法通过开发新的⻣⼲⽹和修改整体⽹络架构来改进点云学习，但我们的⼯作重点是点云转换器的注意⼒机制。我们的⽬标不是为点云学习提出新的架构，⽽是提供⼀种与模型⽆关的解决⽅案

2. 点云对象检测：点云⽬标检测的⼀个主要挑战是提取⽬标特征
    1. 常见做法：
        - 在⼆维⽬标检测中，提取⽬标特征的⼀种常⻅做法是使⽤[区域建议⽹络（region proposal network，RPN）](https://zhuanlan.zhihu.com/p/106192020)以⾃上⽽下的⽅式⽣成密集的边界框建议（即对象可以确定），然后提取特征每个候选对象

        - 问题：然⽽，在 3D 视觉中，由于点云的不规则性和稀疏性，为点云数据⽣成密集的 3D 边界框建议是低效的
    
    2. 历史解决方法：
        - 之前的⼯作通过将点云投影到 2D ⻦瞰图或体素中然后应⽤RPN 来解决这个问题。然⽽，这样的投影操作会导致⼏何信息的丢失或引⼊量化错误。另⼀项⼯作寻求以⾃下⽽上的⽅式（即基于点）⽣成 3D 提案

        - VoteNet从点云中采样⼀组点作为初始候选对象，然后通过投票将点分配给每个候选对象。每个候选⼈的对象特征是通过在其相应的投票集群（即组）内聚合特征来学习的。后续⼯作不采⽤投票和分组，⽽是建议使⽤Transformer来⾃动建模候选对象和点云之间的关系。尽管基于点的⽅法没有体素化引起的量化误差，但为了使计算可⾏，需要在开始时对点云进⾏⼴泛的下采样模型。这种下采样也会导致⼏何信息的丢失，⽽对象检测具有细粒度的特征以做出准确的预测是很重要的。我们的⼯作基于基于点的Transformer检测器。我们通过在不增加计算预算的情况下构建更⾼分辨率的特征来解决下采样问题

    3. 2D 和 3D 视觉转换器的分层设计
        - 已经做了⼤量的⼯作来使Transformer适应视觉识别。⼀个⽅向是借鉴卷积神经⽹络 (ConvNet) 的分层设计和归纳偏差。在 2D 视觉中，⼀⾏基于 ConvNet 的分层设计通过逐渐降低分辨率和扩展特征通道为 2D 图像⽣成多尺度特征图

        - Swin Transformer采⽤了 ConvNet 的权重共享思想，并提出了具有移位窗⼝的⾼效⾃注意⼒。分流⾃注意⼒通过多尺度令牌聚合关注不同尺度的特征。在 3D 视觉中，之前的⼯作探索了点云Transformer的分层设计，其中将⾃注意⼒应⽤于局部区域（由k最近邻或给定半径指定），并执⾏下采样操作在遵循PointNet++的分层设计的每个编码阶段之后。 Patchformer提出了⼀种多尺度注意⼒块，可以在多个粒度上执⾏提取特征，但它需要在点云上进⾏体素化。与以前的⼯作不同，我们将我们的分层设计打包到与模型⽆关的注意⼒模块中，这些模块可以插⼊任何现有的体系结构中，并⽀持多尺度和局部特征学习

# 三、设计的模型
- 在本节中，我们首先讨论背景，包括对点云对象检测任务的简要介绍、基于点的3D检测方法的概述以及注意机制。接下来，我们将深入研究我们提出的注意力模块的详细设计

1. 背景
    1. 点云对象检测
        - 给定具有一组 $P$ 点 $\mathcal{P} ＝ \lbrace \mathbf{p_ {i}} \rbrace^{P}_ {i=1}$ 的点云 $\mathcal{P}_ {raw}$ ，每个点 $p_ {i} \in \mathbb{R}^{3}$ 由其三维坐标表示。点云上的3D对象检测旨在预测场景中对象的一组边界框，包括它们的位置（作为边界框的中心）、边界框的大小和方向以及相应对象的语义类。注意，由于计算限制，点云在模式的早期被下采样到 $\mathcal{P}_ {raw}$ 的子集，其中包含 $N(N < < P)$ 个点。 $\mathcal{P} ＝ \mathbf{SA}（\mathcal{P}_ {raw}）＝｛\lbrace \mathbf{p_ {i}} \rbrace^{N}_ {i=1}$ 包含 $N$ 个组中心周围的点的聚合组，其中 $\mathbf{SA}$ （集合抽象）是聚合函数，组中心使用最远点采样（Furthest Point Sample, FPS）从原始点云采样，该随机采样算法提供了整个点云的良好覆盖

    2. 基于点的三维物体探测器
        - 我们的方法基于基于点的3D对象检测器，该检测器以自下而上的方式检测点云中的3D对象。与在鸟瞰图或体素化点云上以自顶向下的方式生成框建议的其他3D检测器相比，基于点的方法直接在不规则点云上工作，不会导致信息丢失或量化误差。此外，基于点的方法适用于更有效的单级目标检测

        - 首先使用主干模型（例如，PointNet++）获得输入点云 $\lbrace \mathbf{z_ {i}} \rbrace^{N}_ {i＝1}，\mathbf{z_ {i}} \in \mathbb{R}^{d}$ 的特征表示，其中 $d$ 是特征维度。基于点的检测器生成以 $M(M < N)$ 个初始对象候选 $\lbrace \mathbf{q_ {i}} \rbrace^{M}_ {i＝1}，\mathbf{q_ {i}} \in \mathbb{R}^{C}$ 为起点的边界框预测，从点云采样作为对象中心。对候选对象进行采样的常用方法是最远点采样（FPS）。一旦获得初始候选，检测器就提取每个候选对象的特征。基于注意力的方法通过在对象候选之间进行自我关注以及在候选（i.e., query）和点特征 $\lbrace \mathbf{z_ {i}} \rbrace^{N}_ {i＝1}$ 之间进行交叉关注来学习特征。然后，对象候选的学习特征将传递给预测头，预测头预测每个对象候选的边界框的属性。3D边界框的属性包括其位置(框中心) $\hat{\mathbf{c}} \in \mathbb{R}^{3}$ 、大小(H/W/D维度) $\hat{\mathbf{d}} \in \mathbb{R}^{3}$ 、方向(航向角) $\hat{\mathbf{a}} \in \mathbb{R}$ 和对象的语义标签 $\hat{\mathbf{s}}$ 。通过这些参数化，我们可以将边界框建议表示为 $\hat{\mathbf{s}} = \lbrace \hat{\mathbf{c}}，\hat{\mathbf{d}}，\hat{\mathbf{a}}，\hat{\mathbf{s}} \rbrace$ 。边界框的详细参数化包括在附录 $\color{red}{A.2}$ 中
    
    3. 注意机制
        - 注意机制是Transformer的基本组成部分。注意力函数将查询（ $Q$ ）、键（ $K$ ）和值（ $V$ ）作为输入。注意力函数的输出是值的加权和，注意力权重是键和查询之间的缩放点积： $$\begin{align} Attn(Q,K,V) = softmax(\frac{QK^{T}}{\sqrt{d_ {h}}})V \end{align}$$ 其中 $d_ {h}$ 是关注层的隐藏维度。对于自注意力， $Q \in \mathbb{R}^{d_ {h}}$ 、 $K \in \mathbb{R}^{d_ {h}}$ 和 $V \in \mathbb{R}^{d_ {v}}$ 分别从输入 $X \in \mathbb{R}^{d}$ 通过参数矩阵 $W^{Q}_ {i} \in \mathbb{R}^{d \times d_ {h}}$ 、 $W^{K}_ {i} \in \mathbb{R}^{d \times d_ {h}}$ 和 $W^{V}_ {i} \in \mathbb{R}^{d \times d_ {v}}$ 的线性投影进行变换。对于交叉关注， $Q$ 、 $K$ 和 $V$ 可以有不同的来源

        - 在实践中，变压器采用多头注意力设计，其中多个注意力功能在不同的注意力头上并行应用。每个注意力头部的输入是层输入的一部分。具体而言，查询、键和值沿着隐藏维度被拆分为 $(Q_ {i}，K_ {i}，V_ {i})^{h}_ {i=1}$ ，其中 $Q_ {i} \in \mathbb{R}^{d_ {h} / h}，K_ {i} \in \mathbb{R}^{d_ {h} / h}，V_ {i} \in \mathbb{R}^{d_ {v} / h}$ ，其中 $h$ 是关注头的数量。多头注意力层的最终输出是所有注意力头的连接输出的投影： $$\begin{align} MultiHead(Q,K,V)  = Concat(\lbrace Attn(Q_ {0}, K_ {0}, V_ {0}); \dots ; Attn(Q_ {h−1}, K_ {h−1}, V_ {h−1}) \rbrace )W^{O} \end{align}$$ 其中第一项表示输出的级联， $W^{O}$ 是输出投影矩阵

2. 简单多尺度注意力
    - 当将Transformer应用于基于点的3D对象检测时，交叉注意力对对象候选和点云中所有其他点之间的关系进行建模。直觉是，对于每个候选对象，点云（(i.e., scene）中的每个点都属于该对象，或者可以为该对象提供上下文信息。因此，收集每个对象候选的所有点特征是有意义的，并且点对对象候选的重要性可以通过关注权重来确定

    - 然而，由于注意力函数的计算开销，模型学习的实际点数（i.e., tokens）设置为1024，而原始点云通常包含数万个点。在点云上进行如此广泛的下采样会导致丢失详细的几何信息和细粒度特征，这对于像对象检测这样的密集预测任务非常重要

    - 为此，我们提出了简单多尺度关注（Simple Multi-Scale Attention，MS-A），它从单尺度特征输入构建更高分辨率（i.e., higher point density）的特征图。然后，它使用两个尺度的特征作为对象候选和其他点之间的交叉关注的关键和值。我们的目标是创建一个更高分辨率的特征地图，提供点云的细粒度几何细节

    - 我们多尺度关注的第一步是从单尺度输入中获得更高分辨率的特征图。我们提出了一种可学习的上采样操作。给定层的输入点云特征 $\lbrace \mathbf{z_ {i}} \rbrace^{N}_ {i＝1}, \mathbf{z_ {i}} \in \mathbb{R}^{d}$ ，我们希望创建具有 $2N$ 个点的特征图。为了获得 $2N$ 个点的位置（i.e., coordinates），我们使用FPS从原始点云 $\lbrace \mathbf{p_ {i}} \rbrace^{2N}_ {i＝1}, \mathbf{p_ {i}} \in \mathbb{R}^{3}$ 中采样 $2N$ 个。接下来，对于每个采样点 $\mathbf{p_ {i}}$ ，我们搜索输入特征图 $\lbrace \mathbf{z_ {i}} \rbrace^{N}_ {i＝1}$ (表示为 $\lbrace z^{0}_ {i}，z^{1}_ {i}，z^{2}_ {i} \rbrace$ )中其最近邻居的前三个（在欧氏距离中）。然后，我们计算三点特征的加权插值，通过它们到采样点的距离的倒数进行加权。然后将插值特征投影到采样点的特征表示中。上采样点特征图可以写成： $$\begin{align} \lbrace \mathbf{\hat{z_ {i}}} \rbrace^{2N}_ {i=1}, \mathbf{\hat{z_ {i}}} = \Phi _ { \theta }(\mathrm{interpolate}(\lbrace z^{0}_ {i}，z^{1}_ {i}，z^{2}_ {i} \rbrace)) \end{align}$$ 这里，$\Phi _ {\theta}$ 是由 $\theta$ 参数化的可学习投影函数。我们选择MLP作为投影函数

    - 在上采样之后，我们有两组不同尺度的点特征 $\lbrace \mathbf{z_ {i}} \rbrace^{N}_ {i＝1}，\lbrace \mathbf{\hat{z_ {i}}} \rbrace^{2N}_ {i＝1}$ 。为了避免计算量的增加，我们通过使用不同关注头上的不同尺度的特征，在一次扫描中对两组点特征执行多头交叉关注。我们将注意力头平均分为两组，并在第一组中使用 $\lbrace \mathbf{z_ {i}} \rbrace^{N}_ {i＝1}$ 来获得 $K$ 和 $V$ ，而在第二组中使用另一个。这两个组共享从 $\lbrace \mathbf{q_ {i}} \rbrace^{M}_ {i＝1}$ 转换的同一组查询。由于该模块的输入和输出与普通注意力模块相同，我们可以将 $\mathbf{MS-A}$ 插入任何基于注意力的模型，以实现不同尺度的特征学习。在实践中，我们仅在变压器的第一层应用 $\mathbf{MS-A}$ ，这对网络进行了最小的修改，并引入了很少的计算开销

3. 大小自适应局部注意
    - 尽管注意机制可以对每个点对之间的关系进行建模，但不能保证所学习的模型将比不关注的点更关注对对象重要的点（例如，属于对象的点）。另一方面，变压器中缺乏层次结构，不支持显式局部特征提取。与在固定区域内执行的现有局部注意不同，我们提出了大小自适应局部注意（ Size-Adaptive Local Attention, local-a），它基于边界框建议的大小来定义局部区域

    - 我们首先生成具有对象候选（ $\lbrace \mathbf{q_ {i}} \rbrace^{M}_ {i＝1}$ ）的特征的中间边界框建议 $\lbrace \mathbf{\hat{b_ {i}}} \rbrace^{M}_ {i＝1}$ 。然后，我们在每个候选 $\mathbf{q_ {i}}$ 和从其对应的框建议 $\mathbf{\hat{b_ {i}}}$ 内采样的点之间执行交叉关注。因此，我们为每个查询点定制了大小自适应局部区域。对于每个输入对象候选 $\mathbf{q_ {i}}^{l} \in \mathbb{R}^{d}$ ，将其更新为Local-A： $$\begin{align} \mathbf{q_ {i}}^{l+1} = \mathrm{Attn}(Q^{l}_ {i},K_ {i},V_ {i}), \mathrm{where} \end{align}$$ $$\begin{align} Q^{l}_ {i} = \mathbf{q_ {i}}^{l} W^{Q}, K_ {i} = Z_ {i} W^{K}, V_ {i} = Z_ {i} W^{V}, \mathrm{with} \end{align}$$ $$\begin{align} Z_ {i} = \lbrace \mathbf{z_ {k}}^{i} | pos(\mathbf{z_ {k}}^{i}) in \mathbf{\hat{b_ {i}}} \rbrace, \mathbf{\hat{b_ {i}}} = \mathrm{Pred}^{l}_ {box}(\mathbf{q_ {i}}^{l}) \end{align}$$ 在方程（6）中，我们使用 $pos(·)$ 表示3D空间中一个点的坐标，而 $Z_ {i}$ 是框 $\mathbf{\hat{b_ {i}}}$ 内的一组点。注意，点特征 $\lbrace \mathbf{z_ {i}} \rbrace^{N}_ {i＝1}$ 由主干网络提取，并且在对象候选的特征学习期间不被更新。 $\mathrm{Pred}^{l}_ {box}$ 框是生成中间框预测的 $l$ 层预测头

    - 由于对象候选（i.e., query）将根据其边界框建议的大小具有不同的键和值集，因此每个对象候选的 $K$ 和 $V$ 标记的数量也不同。为了允许批量计算，我们为采样过程设置了最大点数（ $N_ {local}$ ），并将 $N_ {local}$ 用作每个查询点的固定令牌长度。对于包含少于 $N_ {local}$ 个点的边界框，我们用未使用的标记填充点序列到 $N_ {local}$ ，并在交叉关注函数中屏蔽未使用的符号；对于包含 $N_ {local}$ 以上个点的边界框，我们随机丢弃它们，并截断序列以将 $N_ {local}$ 个点作为关键字和值。最后，在边界框为空的情况下，我们围绕对象候选执行球查询，以采样 $N_ {local}$ 个点

    - 与MS-A相同，Local-A不会对模块输入提出额外要求，因此我们可以将其应用于变压器的任何层。具体来说，我们在变压器的末端应用Local-A，其中边界框建议通常更准确


# 四、实验结果
1. 主要结果
    1. 数据集

    2. 评估指标

    3. 基线

    4. 实施细节

    5. 结果

2. 定性结果

3. 对不同大小对象的性能

4. 消融实验
    1. MS-A和Local-A的独立效果

    2. Local-A中的最大点数（ $N_ {local}$ ）

    3. 具有不同功能分辨率的MS-A

## 1、比之前模型的优势

## 2、有优势的原因

## 3、改进空间

# 五、结论

- 在这项工作中，我们提出了简单多尺度注意力和大小自适应局部注意力，这两个模型无关的模块为现有的基于变压器的3D检测器带来了分层设计。我们通过改进的注意力功能实现多尺度特征学习和显式局部特征聚合，这些功能是通用模块，可应用于任何现有的基于注意力的网络，用于端到端训练。我们在两个具有挑战性的室内3D检测基准上改进了最先进的变压器检测器，在小物体上的改进幅度最大。

- 由于我们的注意力模块促进细粒度特征学习，这对于各种密集预测视觉任务很重要，因此未来工作的一个方向是调整我们的注意力模型以解决其他点云学习问题，例如分割。另一个方向是向多尺度注意力引入更有效的注意力机制，以进一步降低计算开销。

## 1、模型是否解决了目标问题

## 2、模型是否遗留了问题

## 3、模型是否引入了新的问题

# 六、代码

# 读者角度（挖掘文章中没有提到的）：
1. 总结文章发现问题的思路
2. 总结文章改进的思想
3. 总结文章还存在或者可以改进的问题
4. 提出对模型参数和细节的一些思考和讨论
