# 论文信息
- 时间：2023
- 期刊：CVPR
- 网络/算法名称：MV2D
- 意义： ***多视图*** 2D物体引导的3D物体检测器
- 作者：Zitian Wang1, Zehao Huang2, Jiahui Fu1, Naiyan Wang2, Si Liu1; 1Institute of Artificial Intelligence, Beihang University 2TuSimple
- 实验环境：
- 数据集： nuScenes dataset
# 一、解决的问题
1. 早期的单眼 3D 对象检测方法通常在2D 对象检测管道之后构建它们的框架；但它们⽆法利⽤周围摄像机的⼏何配置和多视图图像对应关系，⽽这些对于现实世界中物体的 3D 位置⾄关重要。此外，使这些⽅法适应多视图设置依赖于复杂的交叉相机后处理，这进⼀步导致效率和功效下降
2. 多视⻆ 3D ⽬标检测⽅法主要可分为两类：稠密 3D ⽅法和稀疏查询⽅法
    1. 稠密 3D ⽅法：密集 3D ⽅法将多视图特征渲染到 3D 空间中，例如⻦瞰图 (BEV) 特征空间或体素特征空间
    2. 稀疏查询⽅法：基于查询的⽅法[24,39]采⽤可学习的对象查询来聚合来⾃多视图图像的特征，并根据查询特征预测对象边界框。虽然固定数量的对象查询避免了计算成本随 3D 空间爆炸，但查询数量和位置依赖于经验先验可能会导致动态场景中的误报或未检测到的对象
    3. 本⽂中寻求⼀种更可靠的⽅法来动态⽣成对象查询。它可以为图像空间中的⽬标定位⽣成⾼质量的 2D 边界框。幸运的是，3D 检测器通常建⽴在 2D 检测主⼲之上。⼀个⾃然的想法是将每个 2D 检测变成对以下 3D 检测任务的⼀个查询。通过这种⽅式，我们设计了多视图 2D 对象引导 3D 对象检测器 (MV2D)，它可以为任何 2D 检测器配备 3D 检测能⼒，并且 3D 检测器可以收获 2D 检测领域的所有进步




# 二、做出的创新
1. 设计的模型：
    1. 现有⽅法：主要从多视图图像建⽴ 3D 表⽰并采⽤密集的检测头进⾏对象检测，或者使⽤分布在 3D 空间中的对象查询来定位对象
    2. 本文方法：设计了多视图 2D 对象引导 3D 对象检测器 (MV2D)，它可以配备任何 2D 对象检测器以促进多视图 3D 对象检测
    3. 优势：由于 2D 检测可以为对象存在提供有价值的先验信息，MV2D 利⽤ 2D 检测器⽣成以丰富的图像语义为条件的对象查询。这些动态⽣成的查询使 MV2D 能够在不增加计算成本的情况下检测更⼤ 3D 空间中的对象，并显⽰出强⼤的 3D 对象定位能⼒
    4. 细节：对于⽣成的查询，我们设计了⼀个稀疏的交叉注意模块来强制它们关注特定对象的特征，从⽽降低了计算成本并抑制了噪声的⼲扰
2. 贡献：
    1. 提出了⼀个名为MV2D 的框架，它可以配备任何2D 对象检测器以促进多视图3D 对象检测。具体来说，MV2D 根据 2D 对象检测器的结果⽣成稀疏动态对象查询
    2. 展⽰了来⾃多视图图像中某些相关区域的稀疏动态对象查询和稀疏聚合不会牺牲任何检测性能
    3. 在标准nuScenes 数据集上测试了MV2D，它在 ***单帧*** ⽅法中实现了最先进的性能
# 三、设计的模型

![MV2D structure](../pictures/MV2D%20structure.png)

1. 模型总览
    - 给定 $N$ 个多视图图像 $\mathcal{I} = \lbrace \mathbf{I}_ {v} | 0 \le v < N \rbrace$ ，图像特征图 $\mathcal{F} = {\mathbf{F}_ {v} | 0 \le v < N}$ ，其中 $\mathbf{F}_ {v} \in \mathbb{R}^{H^{f} \times W^{f} \times C}$ ⾸先使⽤主⼲⽹络从输⼊图像中提取。为了获得 2D 物体检测，将 2D 物体检测器，即 ***Faster R-CNN*** ，应⽤于所有输⼊图像，产⽣⼀组 2D 物体边界框 $\mathcal{B} = {\mathbf{B}_ {v} | 0 \le v < N}$ ，其中 $\mathbf{B}_ {v} \in \mathbb{R}^{M_ {v} \times 4}$ 表⽰第 v 个图像中预测的 2D 边界框。 $M_ {v}$ 是检测框的数量。在实践中，⼆维检测器主⼲的权重也可以⽤于后续的特征提取
    - 不同于在整个数据集上采⽤ ***固定对象*** 查询的多视图 3D 对象检测中的常⽤⽅法， MV2D 以输⼊的 ***多视图图像*** 为条件⽣成对象查询。给定预测的 2D 边界框和提取的图像特征，MV2D 使⽤ ***[RoI-Align](https://zhuanlan.zhihu.com/p/73113289)*** 来提取 2D 对象特征。然后将 **⼆维对象特征** 连同 **相应的边界框** 和 **相机参数** ⼀起放⼊ **动态对象查询⽣成器** 以⽣成对象查询。对于每个 **对象查询** ，通过 **特征选择模块** 根据⼆维检测结果和相机参数选择多视图图像中的相关图像特征。然后对象查询相互交互，并通过 **变换器解码器** 层迭代地集成来⾃相关对象特征的信息。最后，⼀个简单的 **前馈⽹络 (FFN) 头** ⽤于⽣成具有更新特征的 3D 对象预测

2. 动态对象查询生成

    ![MV2D  Dynamic object query generator](../pictures/MV2D%20%20Dynamic%20object%20query%20generator.png)

    - 在有效的 2D 物体检测器的帮助下，物体的存在得到了很好的证明，物体的位置被限制在特定的图像区域内，从⽽为 3D 空间中的物体定位提供了有价值的先验。为了从2D检测结果生成对象查询，我们提出了一个动态查询生成器，如图3所示。动态查询生成器为每个RoI导出3D世界空间中的3D参考点 $\mathbf{p}_ {ref} \in \mathbb{R}^{3}$ 。然后，位置编码层根据 $\mathbf{p}_ {ref}$ 生成对象查询
    - 具体来说，给定所有图像的⼆维⽬标检测结果 $\mathcal{B}$ 和图像特征图 $\mathcal{F}$ ，⾸先通过 RoI-Align 提取⽬标 RoI 特征 $\mathbf{O}$ ，其中 $\mathbf{O}_ {v} \in \mathbb{R}^{M_ {v} \times H^{roi} \times W^{roi} \times C}$ 是对应⼆维对象边界框 $\mathbf{B}_ {v}$ ： $$\begin{align} \mathbf{O}_ {v} = ROIAlign (\mathbf{F}_ {v},\mathbf{B}_ {v}) \end{align}$$ 的RoI特征
    - RoI特征 $\mathbf{O}_ {v}$ 包含足够的对象外观信息以推断图像空间中的对象中心位置。然而，直接从RoI特征进一步估计物体深度是困难的。当原始图像空间中的对象区域重新缩放为固定大小的RoI时，原始图像中包含的几何信息会丢失
    - 考虑到这一点，我们对每个RoI应用等效的相机固有变换，使得在不同RoI上进行的重新缩放操作等效于具有不同相机参数的透视投影。因此，RoI坐标系中的一个点可以转换为具有等效相机固有特性的3D世界空间： $$\begin{align} \mathbf{p}_ {3d} = [\mathbf{R} | \mathbf{t}]^{-1} (\mathbf{K}_ {roi})^{-1} \mathbf{p}_ {roi} \end{align} $$ 其中 $\mathbf{p}_ {roi} \in \mathbf{R}^{4}$ （⻬次坐标）代表了 RoI 坐标系中的点， $\mathbf{p}_ {3d} \in \mathbf{R}^{4}$ 代表了 3D 世界空间中的点， $\mathbf{K}_ {roi}$ 是该 RoI 的等效相机内参，[R|t] 是相机外参
    - RoI大小为 $H^{roi} \times W^{roi}$ ，第v个视图中的第i个2D对象边界框是 $\mathbf{B}^{i}_ {v} = (x^{i}_ {min}, y^{i}_ {min}, x^{i}_ {max}, y^{i}_ {max})$ 原始相机固有矩阵为： $$\begin{align} \mathbf{K}_ {v} = \begin{bmatrix} f_ {x} & 0 & o_ {x} & 0 \\ 0 & f_ {y} & o_ {y} & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1  \end{bmatrix} \end{align}$$ 第i个RoI的等效摄像机固有值可表示为： $$\begin{align} \mathbf{K}^{i}_ {v} = \begin{bmatrix} f_ {x} * r_ {x} & 0 & (o_ {x} - x^{i}_ {min}) * r_ {x} & 0 \\ 0 & f_ {y} * r_ {y} & (o_ {y} - y^{i}_ {min}) * r_ {y} & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1  \end{bmatrix} \end{align}$$ 其中 $r_ {x} = W^{roi} / (x^{i}_ {max} - x^{i}_ {min}), r_ {y} = H^{roi} / (y^{i}_ {max} - y^{i}_ {min})$
    - 由于等效相机固有矩阵包含相机和对象的几何属性，我们采用一个小网络来基于RoI特征 $\mathbf{o}^{i}_ {v}$ 和等效相机固有 $\mathbf{K}^{i}_ {v}$ 隐式编码对象位置 $\mathbf{p}^{i}_ {v} \in \mathbb{R}^{4}$ ： $$\begin{align} \mathbf{p}^{i}_ {v} = \mathcal{H}(MLP(Pool(Conv(\mathbf{o}^{i}_ {v}));\mathbf{K}^{i}_ {v})) \end{align}$$ 其中（;）表示特征连接， $\mathcal{H}(\cdot)$ 表示齐次变换
    - 隐式编码的对象位置 $\mathbf{p}^{i}_ {v}$ （可以被视为RoI坐标系中的3D对象位置）然后使用等式(2)中的等效相机内在和相机外在将其转换为3D世界空间。因此，变换后的3D位置用作在3D世界空间中定位对象的参考点首选项
    - 通过这种转换，MV2D生成一组动态参考点 $\mathcal{P}_ {ref} = \lbrace \mathbf{P}_ {ref, v} \in \mathbb{R}^{M_ {v} \times 3} | 0 \le v < N \rbrace$ 基于2D检测和相机配置。然后，这些参考点通过3D位置编码层来初始化一组对象查询 $\mathcal{Q} = \lbrace \mathbf{Q}_ {v} \in \mathbb{R}^{M_ {v} \times C} | 0 \le v < N \rbrace$

3. 相关对象特征选择

    ![MV2D Illustration of relevant region selection](../pictures/MV2D%20Illustration%20of%20relevant%20region%20selection.png)

    - 每个对象仅在输⼊多视图图像内的⼦区域中捕获。为了精确描绘某个对象，对象查询应关注覆盖⽬标对象的所有相关图像区域，并丢弃可能误导⽬标对象 3D 定位的不相关区域
    - 为此，我们建议为每个对象查询的更新选择相关特征。由于2D对象检测器可以预测令人信服的2D对象建议，因此检测到的对象边界框暗示哪个区域包含关于对象的最独特的信息。因此，我们考虑对象的两部分相关特征：
        1. 生成对象查询的2D边界框 $\mathbf{b}^{i}_ {v}$
        2. 其他视图中与 $\mathbf{b}^{i}_ {v}$ 对应的边界框
    - 在本文中，我们开发了一种有效的方法来关联给定查询的其他视图中的边界框。如图4所示，我们为每个RoI创建了一个3D网格 $\mathbf{G} \in \mathbb{R}^{W^{roi} \times H^{roi} \times D \times 4}$ 。我们将 $\mathbf{g}_ {x，y，z} = (x \times d_ {z}, y \times d_ {z}, d_ {z}，1)$ 表示为网格中的每个点，其中 $(x，y)$ 是RoI中的坐标， $d_ {z} \in {d_ {0}，d_ {1}，\dots ，d_ {D - 1}}$ 是一组预先定义的深度值。然后将RoI网格转换为第w个视图的坐标系： $$\begin{align} \mathbf{g}^{i}_ {v \to w;x,y,z} = \mathbf{K}_ {w} \mathbf{T}_ {v \to w} (\mathbf{K}^{i}_ {v})^(-1) \mathbf{g}_ {x,y,z} \end{align}$$ 其中 $\mathbf{g}^{i}_ {v \to w;x,y,z}$ 是第w个视图中的变换网格点， $\mathbf{T}_ {v \to w}$ 是从第v视图到第w视图的坐标变换矩阵
    - 根据变换后的网格 $\mathbf{G}^{i}_ {v \to w}$ ， 可以计算第w视图的图像空间中的最小边界框 $\mathbf{b}^{i}_ {v \to w}$ 。然后检测到在并集上具有最高交集（IoU）的长方体与 $\mathbf{b}^{i}_ {v \to w}$ （如果大于0）被选择为第w个视图中的相关框： $$\begin{align} \mathbf{b}^{i}_ {corr,v \to w} = \underset{\mathbf{b}^{i}_ {w} \in \mathbf{B}_ {w}}{argmax} \mathbf{IOU}(\mathbf{b}^{i}_ {v \to w}, \mathbf{b}^{j}_ {w}) \end{align}$$ 那么，只有 $\mathbf{b}^{i}_ {v}$ 和 $\lbrace \mathbf{b}^{i}_ {corr, v \to w} | 0 \le w < N, w \neq v \rbrace$ 的ROI特征会被采用去更新查询 $\mathbf{q}^{i}_ {v}$ 。我们会在后边的章节中详细描述这里的细节

4. 具有稀疏交叉注意⼒的解码器
    - 生成的对象查询通过类似DETR的变换器解码器与其相关特征交互。根据PETR，为相关特征提供3D位置嵌入。我们解码器的不同之处在于稀疏的交叉关注层，如图2所示。MV2D没有使用整个多视图特征映射来构造所有查询共享的键和值，而是仅使用相关特征来构造每个对象查询的自己的键和数值。这种设计不仅提供了一组紧凑的键和值，还防止了对象查询受到背景噪声和干扰因素的干扰
    - 最后，我们将由MLP组成的分类头和回归头应用于更新的对象查询，以预测最终的3D对象检测结果

5. 损失函数
    - 在我们的实现中，2D检测器和3D检测器在MV2D中联合训练，在两个检测器之间共享主干权重。2D对象检测损失 $\mathcal{L}_{2d}$ 直接取自2D检测器。关于3D对象检测损失，我们遵循先前的工作，使用匈牙利算法进行标签分配。焦点损失和L1损失分别用于分类和盒回归。3D对象检测损失可概括为： $$\begin{align}  \mathcal{L}_ {3d} = \lambda _ {cls3d} \cdot \mathcal{L}_ {cls3d} + \mathcal{L}_ {reg3d} \end{align}$$ MV2D的总损失函数为： $$\begin{align}  \mathcal{L} =  + \mathcal{L}_ {2d} + \lambda _ {3d} \cdot \mathcal{L}_ {3d} \end{align}$$ 其中 $\lambda _ {3d}$ 是平衡2D检测和3d检测损失的权重项，在我们的实验中设置为0.1


# 四、实验结果
1. 数据集和指标(说明网络参数)
2. 实施细节(对比不同主干网络)
3. 与最先进技术的⽐较(证明单帧模式牛逼)
4. 消融实验(在 ResNet-50 主⼲下，⽤动态⽣成的查询牛逼，另外还验证了对象查询在指定前景区域聚合信息的有效性)
5. 定性分析(2D 对象检测器可以充分利⽤图像语义来发现对象来⾃图像空间的项⽬，可以作为对象存在的可靠证据，供 3D 检测器利⽤，且，更好的初始化查询和受限搜索区
域可能有助于减少定位对象的歧义)
## 1、比之前模型的优势
- 在本⽂中，我们提出了⽤于多视图 3D 对象检测的多视图 2D 对象引导 3D 对象检测器 (MV2D)。在我们的框架中，我们利⽤ 2D 对象作为稀疏查询，并采⽤稀疏交叉注意模块来限制查询的注意区域。在我们的实验中，我们使⽤我们提出的稀疏动态对象查询和稀疏聚合策略在 nuScenes 数据集上展⽰了有希望的结果。我们的框架可以为任何 2D 检测器配备 3D 检测能⼒，我们相信利⽤ 2D 对象作为指导的洞察⼒可以进⼀步激发多视图 3D 对象检测⽅法的设计
## 2、有优势的原因

## 3、改进空间
- 局限性由于 MV2D 从 2D 检测⽣成对象查询，因此如果 2D 检测器未能召回对象，则可能会错过该对象。此外，它需要在多帧设置下仔细设计 MV2D 的时间相关性。我们期待将来在时间维度上进⼀步扩展 MV2D

# 五、结论

## 1、模型是否解决了目标问题

## 2、模型是否遗留了问题

## 3、模型是否引入了新的问题

# 六、代码

# 读者角度（挖掘文章中没有提到的）：
1. 总结文章发现问题的思路
2. 总结文章改进的思想
3. 总结文章还存在或者可以改进的问题
4. 提出对模型参数和细节的一些思考和讨论