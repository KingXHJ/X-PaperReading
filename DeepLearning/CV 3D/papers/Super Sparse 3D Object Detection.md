# 论文信息

- 时间：2023
- 期刊：CVPR
- 网络/算法名称：
- 意义：点云网络，超稀疏特征，实现远距离3D目标检测
- 作者：Lue Fan, Yuxue Yang, Feng Wang, Naiyan Wang, and Zhaoxiang Zhang
- 实验环境：
- 数据集：Waymo Open Dataset; Argoverse 2 dataset

# 一、解决的问题

![Super Sparse 3D Object Detection figure1](../pictures/Super%20Sparse%203D%20Object%20Detection%20figure1.png)

1. 以前的⽅法可以根据其空间稀疏性分为三类：密集检测器、稀疏检测器和半密集检测器

    1. 基于体素的密集检测器（它们将稀疏点云转换为密集特征图）：
        - 卷积神经⽹络：开创性⼯作 3DFCN 和 VoxelNet 使⽤密集卷积进⾏体素特征提取。他们将卷积神经⽹络带到了基于激光雷达的 3D 物体检测领域

        - 2D 密集卷积： MV3D 、 PIXOR 和 PointPillars 在⻦瞰图 (BEV) 特征图中采⽤ 2D 密集卷积，实现了显着的效率提升

    2. 基于点的稀疏检测器（纯基于点的检测器天⽣就是完全稀疏的）：
        - ⾃ PointNet 和 PointNet++ 揭⽰了 3D 点集的深度学习以来，⼀系列基于点的检测器应运⽽⽣。这些纯基于点的检测器天⽣就是完全稀疏的

        - PointRCNN 是这⽅⾯⼯作的开创性⼯作

        - 3DSSD 通过移除特征传播层和细化模块来加速基于点的⽅法

        - VoteNet ⾸先进⾏中⼼投票，然后从投票的中⼼⽣成提案，以实现更⾼的准确性

        - 尽管许多⽅法都试图加速基于点的⽅法，但耗时的点采样和邻域查询在⼤规模点云（每个场景超过 100k 点）中仍然⽆法承受。因此，当前具有⼤规模点云的基准仍然由基于体素的密集/半密集检测器主导

    3. 半密集探测器（与密集检测器不同，半密集检测器结合了稀疏特征和密集特征）:
        - SECOND 采⽤稀疏卷积提取 3D 空间中的稀疏体素特征，然后将其转换为 BEV 中的密集特征图以扩⼤感受野并与 2D 检测头集成。基于 SECOND 式半密集检测器，⼀系列⼯作对单级范式进⾏了进⼀步改进。其他⽅法附加了第⼆阶段，⽤于细粒度特征提取和提案细化，实现了卓越的性能。尽管半密集检测器在学术界和⼯业界占据主导地位，但相关研究在这⾥停滞不前，因为半密集检测器不能被简单地提升为完全稀疏

2. 现在的方法和局限：主流 3D 对象检测器通常构建密集的特征图，其中成本与感知范围成⼆次⽅，这使得它们很难扩展到远程设置

3. 本文提出的方法：为了实现⾼效的远程检测，我们⾸先提出了⼀种称为 FSD 的完全稀疏对象检测器。 FSD 建⽴在通⽤稀疏体素编码器和新颖的稀疏实例识别 (SIR) 模块之上。为了进⼀步享受完全稀疏特性的好处，我们利⽤时间信息去除数据冗余，并提出了⼀种名为FSD++ 的超稀疏检测器。FSD++⾸先⽣成残差点，残差点表⽰连续帧之间的点变化。残差点与之前的⼏个前景点⼀起形成超稀疏输⼊数据，⼤⼤减少了数据冗余和计算开销

4. 思路：鉴于固有的稀疏性，有效的远程检测的⼀个基本解决⽅案是删除密集的特征图并使⽹络架构完全稀疏

![Super Sparse 3D Object Detection figure2](../pictures/Super%20Sparse%203D%20Object%20Detection%20figure2.png)

5. 困难：然⽽，移除密集特征图并⾮易事，因为它在当前设计中起着不可或缺的作⽤。常⽤的稀疏体素编码器只提取⾮空体素上的特征。没有密集的特征图，对象中⼼通常是空的，尤其是对于⼤对象。我们将此问题命名为“中⼼特征缺失 (CFM)” （图2）。 CFM 显着削弱了中⼼体素的表⽰能⼒，甚⾄在某些极端情况下（如超⼤型⻋辆）甚⾄使中⼼特征变得空洞。然⽽，⼏乎所有流⾏的基于体素或⽀柱的检测器都采⽤基于中⼼的分配并依赖中⼼特征，因为它是整个对象的理想表⽰。所以他们必须在稀疏体素编码器之后⾸先将稀疏体素转换为⻦瞰图中的密集特征图。然后他们通过在密集特征图上应⽤卷积将特征扩散到实例中⼼来解决 CFM 问题，我们将其命名为特征扩散（图2）

6. 解决过程的困难：为了正确消除密集的特征图，我们研究了纯基于点的检测器，因为它们⾃然是完全稀疏的。然⽽，两个缺点限制了基于点的⽅法的使⽤:
    - 1. 耗时邻域查询是将其应⽤于⼤规模点云（超过 100K 点）的⻓期难题
    - 2. 为了减少计算开销，基于点的⽅法积极地将整个场景下采样到固定数量的点。激进的下采样导致不可避免的信息丢失和前景对象的召回不⾜，尤其是对于⼩对象。因此，很少有纯基于点的检测器在最近的⼤规模点云基准测试中达到了最先进的性能


# 二、做出的创新

1. 在本⽂中，我们⾸先提出 ***完全稀疏检测器（Fully Sparse Detector， FSD）*** 来回避中⼼特征缺失的问题。 FSD 建⽴在通⽤的稀疏体素编码器之上，⽤于体素/点特征提取。然后 FSD 将这些点分组到⼀个实例中，并进⼀步提取实例级特征并通过新颖的 ***稀疏实例识别 (Sparse Instance Recognition， SIR)*** 模块从集成实例特征中预测单个边界框。通过这种⽅式，预测是根据整个实例特征⽽不是弱或缺失的中⼼特征进⾏的。作为⼀个基于点的模块，SIR 有⼏个理想的特性：
    - 1. 与以前的基于点的模块不同，SIR 简单地将实例视为组，并且不应⽤耗时的邻域查询来进⼀步分组

    - 2. 类似于动态体素化， SIR利⽤动态⼴播/池化进⾏张量操作，以避免点采样或填充

    - 3. 由于SIR 中的组覆盖了整个实例，因此⽆论实例的物理⼤⼩如何，它都会构建⼀个⾜够的感受野

2. 为了释放 FSD 的全部潜⼒，我们进⼀步利⽤ ***时间信息*** 并提出了⼀个名为 FSD++ 的超稀疏 3D 对象检测器。 FSD++ 受到⼈类视觉⾏为的启发：⼈类对物理世界的动态部分很敏感，也很关注。特别是，FSD++ 利⽤⾃我运动去除包含⼤量时间冗余的静态部分，同时仅保留信息丰富的动态部分。我们将 ***检测到的动态部分命名为残差点*** ，因为该过程类似于应⽤帧之间的差异。通过这种⽅式，我们创建了⼀个超稀疏点云，由残差点和少量来⾃历史预测的过去前景点组成。 FSD++然后将超稀疏点云作为输⼊，实现了⼀个⾮常具有时间融合的⾼效检测框架。我们将⾼效率归功于完全稀疏特征和超稀疏输⼊的协同作⽤。我们列出了我们的贡献如下：

    - 我们引⼊了完全稀疏检测器(FSD) 的概念，这是⾼效远程 LiDAR 检测的基本解决⽅案。我们进⼀步提出稀疏实例识别（SIR）来回避稀疏特征图中中⼼特征缺失（CFM）的问题。将 SIR 与⼀般稀疏体素编码器相结合，我们开发了⼀种⾼效且有效的 FSD 实现

    - 基于 FSD ，我们进⼀步提出了 FSD++ 框架，该框架从多帧中聚合超稀疏点云作为输⼊，同时消除了点云的时间冗余。拟议的框架揭⽰了稀疏架构尚未开发的潜⼒。我们希望我们的努⼒能引起社区对完全稀疏架构的关注

    - FSD 在具有竞争⼒的 Waymo 开放数据集上实现了最先进的性能。此外，我们进⼀步将我们的⽅法应⽤于最近发布的 Argoverse 2 数据集，以证明 FSD 在远程检测中的优势，其中 FSD ⽐其密集对应物更有效。 FSD++ 实现了与主流最先进的多帧检测器相当的性能，与单帧输⼊相⽐具有最⼩的额外开销


# 三、设计的模型
1. FSD：完全稀疏3D物体检测
    1. 总体架构
        - 按照实例作为组的动机，我们有四个步骤来构建完全稀疏检测器（FSD）：
            1. 我们首先利用稀疏体素编码器来提取体素特征并为对象中心投票

            2. 实例点分组根据投票结果将前景点分组为实例

            3. 给定分组结果，稀疏实例识别（SIR）模块提取实例/点特征并生成建议

            4. 建议用于纠正点分组，并迭代细化建议

    2. 实例点编组
        1. 分类和投票
            - 我们首先使用稀疏体素编码器从点云中提取体素特征，例如SST中的稀疏关注块或稀疏卷积编码器。然后，我们通过连接体素特征和从点到其对应体素中心的偏移来构建点特征。这些点特征被分成两个头部，用于前景分类和中心投票。投票类似于VoteNet，其中模型预测从前景点到相应对象中心的偏移。 L1 loss 和 Focal Loss 被用作投票损失 $L_ {vote}$ 和语义分类损失 $L_ {sem}$

        ![Super Sparse 3D Object Detection figure3](../pictures/Super%20Sparse%203D%20Object%20Detection%20figure3.png)

        2. 连接的组件标签(CCL)
            - 为了将点分组到实例中，我们将所有预测的中心（图3中的红色点）视为图中的顶点。如果两个顶点的距离小于某个阈值，则将连接两个顶点。然后，此图中的连接组件可以被视为一个实例，投票给该连接组件的所有点都共享一个组ID。与VoteNet中的球查询不同，我们基于CCL的分组在大多数情况下避免了碎片化实例。尽管有许多精心设计的实例分组方法，我们选择简单的CCL，因为它在我们的设计中是足够的，并且可以通过高效的联合查找算法并行实现

    3. 稀疏实例识别
        
        1. 准备工作：动态广播/汇集
            - 给定 $\mathrm{N}$ 个点属于 $\mathrm{M}$ 个群，我们将其对应的群ID数组定义为 $\mathrm{[N，]}$ 形状的 $I$ ，将其特征数组定义为 $\mathrm{[N，C]}$ 形状的 $F$ ，其中 $\mathrm{C}$ 是特征维度。 $F^{(i)}$ 是属于第i组的点的特征阵列。动态池将每个 $F^{(i)}$ 聚合为形状为 $\mathrm{[C，]}$ 的一个组特征 $\mathbf{g}_ {i}$ 。因此，我们有 $\mathbf{g}_ {i} ＝ p(F^{(i)})$ ，其中 $p$ 是对称的池函数。形状 $\mathrm{[M，C]}$ 的所有群特征 $G$ 上的动态池被公式化为 $G=p(F，I)$ 。动态广播可以看作是动态池的反向操作，它将 $\mathbf{g}_ {i}$ 广播到第i组中的所有点。由于广播本质上是一种索引操作，我们使用索引符号 $\mathrm{[]}$ 将其表示为 $G[I]$ ，其形状为 $\mathrm{[N，C]}$ 。动态广播/池是非常有效的，因为它可以在现代设备上以高并行性实现，并且非常适合具有动态大小的稀疏数据。我们在附录 $\color{red}{A}$ 中提供了高效的实现和运行时评估

            - 动态广播/池的先决条件是每个点唯一地属于一个组，即组不应彼此重叠。由于真实3D世界中实例之间没有重叠，因此组之间自然不会重叠

        2. 稀疏实例识别的公式化
            - 在 "实例点编组" 中将点分组为实例后，我们可以通过一些基于点的基本网络（如PointNet、DGCNN等）直接提取实例特征。有三个元素可以定义基于点的基础模块：组中心、成对特征和组特征聚合

            1. 组中心
                - 组中心是组的代表点。例如，在球查询中，它是球体的本地原点。在SIR中，组中心定义为组中所有投票中心的质心

            2. 成对特征
                - 定义了将组中心点和相邻点输入配对以进行组感知相邻点特征提取的方法。SIR采用两种成对特征：
                    1. 组中心和每个点之间的相对坐标

                    2. 组特征和每个点特征的串联

                  以特征级联为例，使用 "准备工作：动态广播/汇集" 中的符号，成对特征可以表示为 $\mathrm{CAT} (F，G[I])$ ，其中 $\mathrm{CAT}$ 是信道级联

            3. 组特征聚合
                - 在组中，使用池函数来聚合相邻特征。SIR将动态池应用于聚合特征数组 $F$ 。根据 "准备工作：动态广播/汇集" 中的符号，我们得到 $G=p(F，I)$ ，其中 $G$ 是聚合的组特征

            ![Super Sparse 3D Object Detection figure4](../pictures/Super%20Sparse%203D%20Object%20Detection%20figure4.png)

            4. 集成
                - 结合这三个基本元素，我们可以构建基于点的运算符的许多变体，如PointNet、DGCNN、Meta Kernel等。图4说明了如何使用动态广播/池构建实例级点运算符的基本思想。在我们的设计中，我们采用VFE的公式作为SIR层的基本结构，基本上是两层PointNet。在SIR模块的第l层中，给定输入点方向特征阵列 $F_ {l}$、点坐标阵列 $X$ 、投票中心 $X^{'}$ 和组ID阵列 $I$ ，第l层的输出可以公式化为： $$\begin{align} F^{'}_ {l} = \mathrm{LinNormAct} (\mathrm{CAT} (F_ {l}, X - p_ {avg}(X^{'}, I)[I])) \end{align}$$ $$\begin{align} F_ {l+1} = \mathrm{LinNormAct} (\mathrm{CAT} (F^{'}_ {l}, p_ {max}(F^{'}_ {l}, I)[I])) \end{align}$$ 其中 $\mathrm{LinNormAct}$ 是完全连接的层，随后是归一化层和激活函数。 $p_ {avg}$ 和 $p_ {max}$ 分别是平均池和最大池函数。输出 $F_ {l+1}$ 可以进一步用作下一个SIR层的输入，因此我们的SIR模块是两个基本SIR层组成的堆栈

        3. 稀疏预测
            - 根据 等式1 和 等式2 、SIR并行动态提取所有实例的特征。然后SIR对所有组进行 ***稀疏预测*** 。与两阶段稀疏预测不同，我们的建议（即组）彼此不重叠。与单阶段密集预测不同，我们只为一个组生成一个预测，这显著降低了预测头的成本。值得注意的是，完全稀疏的体系结构可能面临严重的不平衡问题：短距离对象包含的点比长距离对象多得多。一些方法使用手工制作的归一化因子来缓解失衡。相反，SIR避免了不平衡，因为它只为一个组生成单个预测，而不考虑组中的点数。在大多数情况下，一个组只对应于一个真值框

            - 具体地，对于每个SIR层，在 等式2 中存在 $G_ {l} = p_ {max} (F^{'}_ {l} ，I)$ ，这可以被视为组特征。我们在信道维度中连接来自每个SIR层的所有 $G_ {l}$ ，并使用连接的组特征通过MLP预测边界框和类标签。中心落入地面真值框的所有组都是阳性样本。对于正样本，回归分支预测从组中心到地面真实中心的偏移以及对象大小和方向。L1 Loss 和 Focal Loss 分别用作 regression loss $L_ {reg}$ 和 classification loss $L_ {cls}$
    
    4. 组更正
        - 实例点分组模块中不可避免地存在错误分组。例如，一些前景点可能被遗漏，或者一些组可能被背景杂波污染。因此，我们利用SIR的边界框建议来纠正分组。方案中的点属于已更正的组，而不管其以前的组ID如何。由于几个要点可能包含多个建议，我们只需为这些要点及其特征制作副本，并将不同的副本分配给不同的建议。校正后，我们对这些新组应用附加SIR。为了区别于第一个安全气囊系统模块，我们将附加的安全气囊系统（SIR）模块表示为SIR2

        - SIR2在许多两级检测器之后，预测从提案到其对应的地面真值框的框残差。为了使SIR2了解提案的大小和位置，我们采用从内部点到提案边界的偏移作为以下额外点特征。回归损失表示为 $L_ {res} = L1(\Delta _ {res} ，\widehat{\Delta _ {res}})$ ，其中 $\Delta _ {res}$ 是地面真实残差， $\widehat{\Delta _ {res}}$ 是预测残差。根据之前的方法，建议和真值之间的3D联合交叉点（IoU）用作SIR2中的软分类标签。具体而言，软标签 $q$ 被定义为 $q = min(1，max(0，2IoU − 0.5))$，其中 $IoU$ 是提案与相应地面事实之间的联合交叉面积（IoU）。然后采用交叉熵损失来训练分类分支，表示为 $L_ {iou}$ 。考虑到分组（"实例点编组"）和稀疏预测中的所有损失函数，我们有 $$\begin{align} L_ {total} = L_ {sem} + L_ {vote} + L_ {reg} + L_ {cls} + L_ {res} + L_ {iou} \end{align}$$ 为了简单起见，我们省略了每个项的权重
    
    5. 讨论
        - FSD中的中心投票受到VoteNet的启发，而FSD与VoteNet有两个本质区别。
            - 投票后，VoteNet只需聚集投票中心周围的特征，无需进一步提取特征。FSD超越了这一点，并利用动态广播/池构建了一个高效的SIR模块，允许进一步的实例级特征提取。因此，FSD提取了更强大的实例特征，这在 第5.5节 中得到了实验证明

            - VoteNet是一种典型的基于点的方法。正如我们在第1节中所讨论的那样，为了提高效率，它会将整个场景积极地降采样到固定数量的点，从而导致不可避免的信息丢失。相反，SIR的动态特性和效率使得能够从任意数量的输入点提取细粒度的点特征，而无需任何下采样。在 第5.5节 中，我们展示了我们的设计在处理大规模点云方面的效率以及细粒度点表示的好处

2. FSD++：具有超稀疏输入的FSD

    - 众所周知，聚合多个帧作为输入有益于性能。然而，天真的聚合可能会导致更密集的点云，这会显著降低算法的速度，尤其是在具有稀疏操作的架构中。这促使我们通过从原始点云流中去除时间冗余来追求更稀疏的输入数据。由于完全稀疏的特性，完全稀疏模型可以从冗余去除后稀疏度的增加中受益匪浅。 ***因此，一个自然的问题出现了：我们如何在事先保留信息部分的同时消除冗余？*** 连续点云框架之间的相似性为我们提供了解决这个问题的潜在方案

    - 特别是，点的空间分布在序列中连续而平滑地变化。我们将连续帧之间变化的点命名为 ***残差点*** 。残余点是信息性的，因为它们代表时间步长中的新观测值。结合残余点和历史预测，检测器具有足够的知识来推断当前对象。在这个范例中，残余点和先前的前景点一起形成一个超级稀疏的点云。FSD可以直接将它们作为输入，以实现更有效的目标检测

    1. 残余点探测
        - LiDAR传感器在每个时间步捕获大量新观察到的前景点。这些点可以归结为两个主要来源：
            1. 物体移动到新位置

            2. 被遮挡的区域变得可见

          这些新观察到的点被称为残余点。残余点对于定位移动物体和检测最近出现的物体至关重要。如前所述，可以从点空间分布的变化中检测残余点
        
        - 残余点检测算法必须满足两个关键要求
            1. 该算法被认为对可能由感知噪声或微小自我运动估计误差引起的点的微小干扰具有鲁棒性。这样的点扰动被检测为残余点是出乎意料的
            2. 该算法应该能够高效地处理来自多个帧的数百万点。特别是，WOD 中的每一帧包含多达200000点

        - 几个简单的解决方案满足第一个要求，即球查询或密集占用地图的体素化。如果之前没有点落入由球查询半径定义的邻域，则可以将点视为残差点。残余点也可以通过两个密集占用图之间的简单差异来检测。尽管适当的球查询半径或体素大小对点扰动具有鲁棒性，但这些解决方案仍然具有较高的计算复杂性 $(O(N^{2}))$ 或者巨大的内存占用

        - 为了满足上面概述的两个需求，我们求助于哈希并设计Algo中所示的 ***算法1*** ，称为 ***残余点探测（RPP）*** 。RPP包括两个步骤：
            1. 它首先将点坐标量化为整数。量化的粒度控制对点扰动的鲁棒性

            2. 对于每个点，RPP通过散列探测来验证它是否是剩余点。具体来说，RPP首先从先前量化的点构建哈希表。哈希表的键集表示为 $K \subset \mathbb{Z}^{3}$ ，这是量化的整数坐标
            
        哈希表的值集表示为 $V = \lbrace 1，0 \rbrace $ ，其中 1 表示插槽被占用，0 表示插槽未被占用。然后，RPP使用当前量化坐标来探测哈希表。如果当前点击中未占用的插槽，则将其视为剩余点。这里是RPP中的一个隐藏假设，即我们假设两个点在量化后占据相同的体素时是相同的。我们采用众所周知的开放寻址进行探测，并将双哈希作为哈希函数，以减少哈希冲突

        - 残余点探测在内存和速度方面都很有效。例如，我们假设点云剪辑中有 $N$ 个唯一的量化坐标。如果我们期望碰撞率小于 $\alpha$ ，则哈希表的长度应为 $N / \alpha$ 。根据经验，WOD 中 5 帧点云中的 $N$ 约为 500000。时隙状态可以表示为单个比特，并使 $\alpha$ 等于0.1。我们知道这个哈希表的内存成本约为0.6MB。此外，每个点的探测彼此独立，允许GPU中的高并行性
        
        - 形式上，我们表示RPP过程如下： $$\begin{align} \Delta P_ {t} = P_ {t} - \bigcup^{B}_ {i=1} P_ {t-i} \end{align}$$ 其中 $\Delta P_ {t}$ 是时间步 $t$ 中检测到的残余点， $P_ {t}$ 是时步 $t$ 中的原始点。符号 “ $X−Y$ ” 表示从 $X$ 中删除$X$ 和 $Y$ 的交点，相当于 $X \backslash (X \cup Y)$ 。联合意味着点云连接。 $B$ 是RPP中使用的先前帧的数量，我们称之为 ***基本帧***

    2. 骨架点采样
        - 由于残差点仅包含当前时间步长的新观测值，因此检测器需要来自先前帧的附加信息以获得足够的输入。为了合并这些历史数据，我们使用先前预测的框来裁剪先前的前景点，同时丢弃框外的其他点。在自我运动补偿之后，裁剪的点被放置到当前帧中。然而，来自多个先前帧的前景点仍然基本上是冗余的。特别是，来自多个帧的短距离对象上的大量点可能会导致不必要的开销

        - 为了减少多帧前景点的冗余，我们在这些裁剪点内进一步采样。直觉上，我们期望采样点包含模型进行正确预测所需的最小信息。在这个意义上，我们将裁剪点的最小子集称为骨架点，因为它们描述了对象的基本结构或“骨架”。具体来说，我们尝试三种采样方法：随机采样、最远点采样和体素采样。所有采样方法都应用于先前预测的边界框内。对于随机采样和最远点采样，我们采用预定义的最大点阈值 $N_ {T}$。我们在包含超过 $N_ {T}$ 个点的边界框内采样 $N_ {T}$ 个点。对于体素采样，我们采用动态体素化对点进行体素化。通过平均池化，落入体素中的所有点都被缩减为单个点

    3. 治疗改变失明

        ![Super Sparse 3D Object Detection figure5](../pictures/Super%20Sparse%203D%20Object%20Detection%20figure5.png)

        - 理论上，通过组合骨架点和残差点，模型能够在当前帧中进行预测。然而，一种被称为“改变盲”的现象可能会阻碍绩效。变化盲是指人类视觉系统倾向于忽略场景中渐进的微小变化，即使多个时间步长的累积变化是显著的。在我们的案例中也可能出现类似的问题。考虑到车辆在时间步 $t$ 接近进入激光雷达的传感范围，只能观察到车辆的一小部分。检测器很可能将其识别为背景，因此RPP将在时间步长 $t+1$ 中删除这些点，并仅保留车辆的少量新点作为残余点。这样，如果车辆缓慢出现，检测器可能永远无法识别它。图5显示了改变的盲目性

        - 为了弥补改变的盲目性，我们引入了残余点的最大年龄 $M$ 。换言之，检测器将来自最多 $M$ 个步骤的残差点作为输入。形式上，检测器将 $\cup^{M-1}_ {i=0} \Delta P_ {t-i}$ 作为时间步长 $t$ 中输入的累积残余点

    4. 集成超级稀疏输入
        - 输入点云由两部分组成：先前的骨架点和来自多个时间步骤的残差点。形式上，对于 $N$ 帧FSD++检测器，我们在时间步 $t$ 中有如下的最终输入点： $$\begin{align} P^{in}_ {t} = ( \bigcup^{N}_ {i=1} P^{s}_ {t-i} ) \cup ( \bigcup^{M-1}_ {i=0} \Delta P_ {t-i} ) \end{align}$$ 其中 $P^{s}_ {t}$ 是时间步长 $t$ 处的骨架点。 $P^{in}_ {t}$ 比原始点云稀疏得多。图7显示了 $P^{s}$ 、 $\Deta P$ 和 $P^{in}$ 的示例

    ![Super Sparse 3D Object Detection figure6](../pictures/Super%20Sparse%203D%20Object%20Detection%20figure6.png)

    ![Super Sparse 3D Object Detection figure7](../pictures/Super%20Sparse%203D%20Object%20Detection%20figure7.png)

    5. 培训和推理管道
        - FSD++的训练和推理管道与标准方法不同，因为它使用了历史预测和时间信息。图6总结了整个管道

        1. 训练
            - 为了利用历史预测，输入点云流必须按时间顺序排列。然而，由于缺乏数据混洗，有序输入流影响模型训练。另一个问题是，在早期训练阶段，历史预测并不可靠。考虑到这两个问题，我们使用训练有素的FSD检测器来生成整个训练集的离线预测。在训练期间，对于每个样本，我们将其与之前的离线预测一起加载到样本骨架点。地面真相箱似乎是离线预测的替代品。然而，训练中使用的地面真相与推理中使用的预测框之间的分布差距相当大。因此，我们采用离线预测，而不是地面真相盒
        
        2. 推理
            - 在在线推断阶段，输入点云流自然是按时间顺序的。对于点云序列，其第一帧的预测来自训练有素的FSD检测器。这些预测被视为第一帧的“先前预测”，称为序列的种子预测。我们维护几个队列来缓存一些可以多次使用的历史数据。例如，在 $N$ 帧FSD++流水线中，可以从时间步长 $t+1$ 到 $t+N−1$ 重用时间步长t的原始点和骨架点


# 四、实验结果
1. 设置
    1. 数据集

    2. 模型配置

    3. 实现细节

2. FSD和FSD++的主要结果

3. 中⼼特征缺失的处理研究
    1. 定量实验
    
    2. 定性分析

4. 远程检测
    1. 主要结果

    2. 范围缩放

5. FSD 的性能检测
    1.  组件的有效性

    2. SIR 中的下采样

    3. 高清地图辅助检测

6. FSD++的综合分析
    1. FSD++分析的初步设置

    2. 骨架点采样

    3. 不同帧数

    4. 漂移分析

    5. 更改盲消融

    6. 种子质量的稳健性

    7. 残余点探测分析
        - 量化大小

        - 底座
7. 详细运行时评估
## 1、比之前模型的优势

## 2、有优势的原因

## 3、改进空间

# 五、结论
- 本文首先提出了一种基于LiDAR的全稀疏三维物体检测框架，即FSD。FSD放弃了先前技术中广泛采用的密集BEV特征图，这是使检测器完全稀疏的障碍。相反，FSD由通用稀疏体素编码器和高效稀疏实例识别（SIR）模块组成。SIR解决了中心特征缺失的问题，这是完全稀疏体系结构的本质难点。FSD不仅在Argoverse 2数据集上实现了高效的远程（高达200米）检测，而且在竞争对手Waymo Open数据集上也实现了最先进的性能

- 为了释放FSD的潜力，我们建议利用时间信息来消除数据冗余。提出的骨架点采样和残余点探测为FSD提供了一个超级稀疏的输入点云，它构成了FSD++框架。FSD++在验证和测试分离Waymo开放数据集上实现了最先进的单模型性能，并保持了高效率。我们希望我们的工作能够为基于激光雷达的点云识别指明未来的研究方向

## 1、模型是否解决了目标问题

## 2、模型是否遗留了问题

## 3、模型是否引入了新的问题

# 六、代码

![Super Sparse 3D Object Detection Algorithm 1](../pictures/Super%20Sparse%203D%20Object%20Detection%20Algorithm%201.png)


# 读者角度（挖掘文章中没有提到的）：
1. 总结文章发现问题的思路
2. 总结文章改进的思想
3. 总结文章还存在或者可以改进的问题
4. 提出对模型参数和细节的一些思考和讨论