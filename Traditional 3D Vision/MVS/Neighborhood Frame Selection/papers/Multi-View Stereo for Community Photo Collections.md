# 论文信息
- 时间：2007
- 期刊：ICCV
- 算法名称：用于社区照片集的多视图立体
- 意义：指导邻域帧的选取
- 作者：Michael Goesele1,2, Noah Snavely1, Brian Curless1, Hugues Hoppe3, Steven M. Seitz1; University of Washington1; TU Darmstadt2; Microsoft Research3
- 实验环境：
- 数据集：
# 前置知识
1. CPC(community photo collections, CPCs)
2. LVS(Local view selection)
# 一、解决的问题
1. 我们提出了一种多视图立体算法，该算法可以解决大型在线社区照片收集中的 ***照明、比例、杂乱（clutter）*** 和其他效果的极端变化
2. 这类网络用户提供的数据提供了一个难得的机会：使用迄今为止已知的最大、最多样且基本上未开发的多视图立体数据集重建世界的几何结构。数据集的与众不同之处不仅在于它的大小，还在于它是在“野外”捕获的，而不是在实验室中捕获的，这给多视图立体研究带来了一系列根本性的新挑战
3. CPCs收集到的图片在色彩表现上和参数上都有很大不同，因为它们是由不同相机在一天的不同时间段拍摄而成
    ![CPC get effected](../pictures/CPC%20get%20effected.png)

4. 此外，选择最近的视图通常是不可取的，因为许多图像几乎相同，因此提供的视差很小
# 二、做出的创新
1. 我们的想法是在每个视图和每个像素级别上智能地选择要匹配的图像。我们表明，这种自适应视图选择即使在外观变化剧烈的情况下也能够实现稳健的性能。立体匹配技术将从运动方法中的结构重构的稀疏3D点作为输入，并从这些点迭代生长曲面。在光一致性度量内优化曲面法线可显著改善匹配结果。虽然我们方法的重点是估计高质量的深度图，但我们也展示了将生成的深度图合并为引人注目的场景重建的示例。我们在标准多视图立体数据集和从互联网收集的著名场景的随机照片集上演示了我们的算法
2. 本文提出了一种立体匹配方法，该方法从视点的不规则分布开始，在存在极端外观变化的情况下生成鲁棒的高质量深度图
3. 前提条件：
    - 考虑到网上可获得的大量图像，在兼容的照明、天气和曝光条件下，以及足够相似的分辨率和足够宽的基线下，任何特定地点都应该有大量的图像子集
4. 需要考察的事：
    1. 在图像级别，以近似匹配比例和外观，并确保足够宽的相机基线
    2. 在像素级，处理杂乱、遮挡和局部照明变化，并促进与水平和垂直视差匹配
5. 受CPC中的特定挑战的激励，我们还提出了一种新的多视图立体匹配算法，该算法使用表面生长方法迭代重建鲁棒和准确的深度图。这种表面生长方法将稀疏特征点作为输入，利用了运动结构技术的成功，这些技术产生了这种输出，最近已证明在CPC上有效运行。我们选择重建 ***亚像素精确的连续深度图*** ，而不是像许多立体方法中常见的那样获得离散深度图。为了极大地提高对源视图中外观差异的恢复能力，我们使用了一种光度窗口匹配方法，在该方法中， ***曲面深度和法线都被一起优化*** ，并且我们自适应地丢弃了不增强匹配窗口的互相关的视图。与深度合并方法结合使用，结果表明，该方法与当前在Middlebury基准上表现最佳的多视图立体重建方法具有竞争力
6. 衡量标准：
    - normalized cross correlation (NCC)
    - 衡量变化的光线、非朗伯反射和巨大的外观变化
    - 注意事项：然而，我们注意到，增加不变性可能会导致区分权重下降，因此应谨慎使用
# 三、设计的算法
1. 算法结构：
    1. 首先对摄像机进行几何和辐射测量校准
    2. 接下来为每一幅输入图像估计一个深度图，每个图像仅用作一次参考视图
    3. 为了找到良好的匹配，我们应用了两级视图选择算法。在图像级别，全局视图选择为每个参考视图识别一组用于立体匹配的良好邻域图像
    4. 然后，在像素级，局部视图选择确定这些图像的子集，以产生稳定的立体匹配。该子集通常随像素而变化
    5. 通过优化深度和法线，从SIFT特征点提供的初始估计或从先前计算的邻居复制的初始估计开始，在每个像素处执行立体匹配。在立体优化期间，根据局部视图选择标准，可以丢弃匹配不良的视图并添加新的视图。像素的遍历由其估计的匹配置信度优先。如果发现更高的置信度匹配，则可以重新访问像素并更新其深度
2. 校准互联网照片
    1. 因为我们的输入图像是从社区照片收集中获取的，所以通常不提供相机姿势、内在特征和传感器响应特性。因此，我们必须首先从几何和辐射两方面校准这组图像
    2. 首先，在可行的情况下，我们使用PTLens从图像中去除径向失真，PTLens是一种商用工具，从图像元数据（EXIF标签）中提取相机和镜头信息，并基于相机和镜头属性数据库校正径向失真。无法校正的图像将自动从CPC中移除，除非我们知道它们不包含显著的透镜畸变（例如，在MVS评估数据集的情况下）
    3. 接下来，将剩余图像输入到稳健的运动度量结构（SFM）系统（基于SIFT特征检测器）中，该系统为所有成功配准的图像产生外部和内部校准（位置、方向、焦距）。它还根据匹配的特征生成稀疏场景重建，并为每个特征生成检测到的图像列表
    4. 为了模拟辐射失真，我们尝试将所有输入图像转换为线性辐射空间。除非捕捉系统的准确响应曲线已知，否则我们假设图像在标准sRGB颜色空间中，并应用逆sRGB映射
3. 视角选择
    1. 全局视角选取
        - 对于每个参考视图 $R$ ，全局视图选择寻求一组 $\mathbf{N}$ 个相邻视图，这些视图在场景内容、外观和比例方面是立体匹配的良好候选。此外，相邻视图应提供关于 $R$ 和彼此的 ***足够视差*** ，以实现稳定的匹配。在这里，我们描述了一个评分函数，该函数设计用于基于这些需求来测量每个候选相邻视图的质量
        - 首先，在SFM阶段重建的共享特征点的数量是给定视图 $V$ 与参考视图 $R$ 的兼容性的良好指标。事实上，具有许多共享特征的图像通常覆盖场景的相似部分。此外，SIFT匹配的成功是一个很好的预测器，像素级匹配也将在图像的大部分区域中成功。特别是，SIFT选择具有相似外观的特征，因此具有许多共享特征的图像总体上倾向于具有相似的外观
        - 然而，共享特征点的数量不足以确保良好的重建。
            - 首先，具有最多共享特征点的视图倾向于几乎并置，因此不能为精确重建提供足够大的基线
            - 第二，SIFT特征检测器的尺度不变性导致实质上不同分辨率的图像很好地匹配，但这种分辨率差异对于立体匹配是有问题的。
        - 因此，我们计算候选邻域 $\mathbf{N}$ （包括 $R$ ）内每个视图V的全局得分 $g_ {R}$ ，作为与 $R$ 共享的特征的加权和： $$\begin{equation} g_ {R}(V) = \sum_ {f \in \mathbf{F}_ {V} \cap \mathbf{F}_ {R}} w_ {\mathbf{N}}(f) \cdot w_ {s}(f) \end{equation}$$ 其中 $\mathbf{F}_ {X}$ 是在视图 $X$ 中观察到的特征点的集合，权重函数如下所述
        - 为了鼓励邻域内的良好视差范围，将权重函数 $w_ {\mathbf{N}}(f)$ 定义为 $\mathbf{N}$ 中所有视图对的乘积： $$\begin{equation} w_ {\mathbf{N}}(f) = \prod_ {\stackrel{V_ {i} , V_ {j} \in \mathbf{N}}{s.t. \quad i \neq j, f \in \mathbf{F}_ {V} \cap \mathbf{F}_ {R}}} w_ {\alpha}(f,V_ {i},V_ {j}) \end{equation}$$ 其中 $w_ {\alpha}(f,V_ {i},V_ {j}) = min((\frac{\alpha}{\alpha _{max}})^{2} , 1)$ ， $\alpha$ 是从 $V_ {i}$ 和 $V_ {j}$ 到 $f$ 的视线之间的角度。函数 $w_ {\alpha}(f,V_ {i},V_ {j})$ 将三角测量角度降到 $\alpha _{max}$ 以下，我们在所有实验中都将其设置为10度。二次加权函数用于抵消随着角度减小而出现的更多特征的趋势。同时，由于共享SIFT特征的相关稀缺性，过大的三角测量角度会自动被阻止
        - 加权函数 $w_ {s}(f)$ 测量特征 $f$ 处图像 $R$ 和 $V$ 的分辨率的相似性。为了估计特征 $f$ 附近的 $V$ 的3D采样率，我们计算以 $f$ 为中心的球体的直径 $s_ {V}(f)$ ，其在 $V$ 中的投影直径等于 $V$ 中的像素间距。我们类似地计算 $R$ 的 $s_ {R}(f)$ 并基于比率 $r = \frac{s_ {R}(f)}{s_ {V}(f)}$ 定义缩放权重 $w_ {s}$ 用： $$\begin{equation} w_ {s}(f) \left\{ \begin{array}{rcl} \frac{2}{r} &     & {2 \leq r} \\ 1 &     & {1 \leq r \le 2} \\ r &     & {r \le 1} \end{array} \right. \end{equation}$$ 该权重函数支持分辨率等于或高于参考视图的视图
        - 定义了视图 $V$ 和邻域 $\mathbf{N}$ 的全局得分后，我们现在可以根据视图得分 $\sum _{V \in \mathbf{N}} g_ {R}(v)$ 的总和找到给定大小（通常 $|\mathbf{N}| = 10$）的最佳 $\mathbf{N}$ 。为了提高效率，我们采用贪心的方法，通过在给定当前 $\mathbf{N}$ （其最初仅包含 $R$ ）的情况下，迭代地将最高得分视图添加到 $\mathbf{N}$ ，从而递增地增加邻域
        - 重新缩放视图：
            - 尽管全局视图选择试图选择具有兼容比例的相邻视图，但由于CPC内分辨率的变化，一定程度的比例不匹配是不可避免的，并且可能对立体匹配产生不利影响。因此，我们试图通过适当的过滤，将所有视图的比例调整到一个共同的、狭窄的范围，无论是全局的还是每个像素的。我们选择前者是为了避免在深度图的不同区域中改变匹配窗口的大小，并提高效率。我们的方法是找到最低分辨率视图 $V_ {min} \in \mathbf{N}$ 相对于 $R$ ，重新采样 $R$ 以近似匹配较低分辨率，然后重新采样较高分辨率的图像以匹配 $V$ 
            - 具体而言，我们基于视图 $V$ 的共享特征来估计视图 $V$ 相对于 $V$ 的分辨率比例： $$\begin{equation} scale_ {R}(V) = \frac{1}{|\mathbf{F}_ {V} \cap \mathbf{F}_ {R}|} \sum _{f \in \mathbf{F}_ {V} \cap \mathbf{F}_ {R}} \frac{s_ {R}(f)}{s_ {V}(f)} \end{equation}$$ 然后， $V_ {min}$ 简单地等于 $argmin_ {V \in \mathbf{N}} scale_ {R}(V)$ 。如果 $scale_ {R}(V_ {min})$ 小于阈值 $t$（在我们的情况下， $t=0.6$ ，这对应于在具有最低相对比例的相邻视图中的3×3窗口上映射5×5参考窗口），我们重新缩放参考视图，以便在重新缩放后， $scale_ {R}(V_ {min}) = t$ 。然后，我们以 $scale_ {R}(V) \ge 1.2$ 的比例重新缩放所有相邻视图，以匹配参考视图的比例（其本身可能已在上一步中重新缩放）。请注意，当继续计算下一个参考视图的深度图时，所有重新缩放的图像版本都会被丢弃
    2. 本地视图选择(LVS)
        - 全局视图选择确定参考视图的一组 $\mathbf{N}$ 个良好匹配候选，并匹配它们的比例。我们不使用所有这些视图在参考视图中的特定位置进行立体匹配，而是选择较小的集合 $\mathbf{A} \subset \mathbf{N}$ 个活动视图（通常 $|\mathbf{A} = 4|$ ）。使用这样的子集自然会加快深度计算
        - 在立体匹配过程中，我们使用一组局部视图选择标准迭代更新 $\mathbf{A}$ ，该标准设计为偏好视图，在给定像素处深度和法线的当前估计的情况下，这些视图在光度上是一致的，并提供足够宽的观察方向范围。为了测量光度一致性，我们使用 $R$ 中给定像素和 $V$ 中相应窗口周围窗口内像素之间的平均去除归一化互相关（NCC）。如果NCC分数高于保守阈值，则 $V$ 是加到 $\mathbf{A}$ 的候选者
        - 此外，我们的目标是 $\mathbf{A}$ 中所有视图之间的视差范围。典型CPC中的视点在3D空间中分布不均匀。大多数图像是从地平面、沿着路径或从有限数量的有利位置拍摄的。至少，正如我们在全局视图选择过程中所做的那样，我们需要避免使用小三角角计算立体。此外，我们希望从不共面的方向观察点。这对于包含许多线条特征的图像（如建筑场景）尤为重要，如果视图沿相似方向分布，则很难进行匹配。例如，水平线要素沿平行于该线要素的线生成一组视点的不确定匹配
        - 我们可以通过观察观察给定场景点（基于参考像素的当前深度估计）的方向跨度来测量角度分布。在实践中，我们转而考虑通过将穿过场景点的每条观看光线投影到参考视图中而获得的对极线的角度扩展。当决定是否将视图 $V$ 添加到活动集 $\mathbf{A}$ 时，我们计算局部得分： $$\begin{equation} l_ {R}(V) = g_ {R}(V) \cdot \prod_ {V^{\prime} \in \mathbf{A}} w_ {e}(V,V^{\prime}) \end{equation}$$ 其中， $w_ {e}(V,V^{\prime}) = min(\frac{\gamma}{\gamma _{max}} , 1)$ ， $\gamma$ 是上述参考视图中极线之间的锐角。我们总是设置 $\gamma _{max} = 10^{\circ}$
        - 然后，局部视图选择算法如下进行。给定像素处的初始深度估计，我们发现具有最高得分 $l_ {R}(V)$ 的视图 $V$ 。如果该视图具有足够高的NCC分数（我们使用0.3的阈值），则将其添加到 $\mathbf{A}$ ；否则将被拒绝。我们重复这个过程，从剩余的未被拒绝的视图中进行选择，直到集合 $\mathbf{A}$ 达到所需的大小或者没有未被拒绝视图。在立体匹配过程中，深度（和法线）被优化，视图可能会被丢弃（并标记为拒绝）。然后，我们尝试添加替换视图，如前所述。很容易看到算法终止，因为拒绝的视图永远不会被重新考虑
    3. 多视图立体重建(Multi-View Stereo Reconstruction)
        - 我们的MVS算法有两部分。
            - 区域增长框架保持匹配候选的优先队列 $Q$ （ $R$ 中的像素位置加上深度和法线的初始值）。并且，匹配系统将匹配候选作为输入，并使用局部视图选择提供的相邻视图计算深度、法线和匹配置信度。如果匹配成功，则将数据存储在深度图、法线图和置信度图中，并将R中的相邻像素作为新的候选像素添加到 $Q$ 中
        1. 区域增长(Region Growing)
            - 区域增长方法背后的理念是，成功匹配的深度样本为 $R$ 中相邻像素位置的深度、法线和匹配置信度提供了良好的初始估计。优化过程是非线性的，具有许多局部极小值，使得良好的初始化至关重要，通常情况下，给定像素处的深度和法线与其相邻像素之一相似。对于非光滑表面或轮廓，此尝试可能会失败
            - 因此，区域增长需要与稳健的匹配过程以及使用不同初始化多次重新访问同一像素位置的能力相结合。为了首先考虑具有更高预期匹配置信度的匹配，对候选进行优先排序很重要。这避免了成长为不可靠的区域，而这些区域又可能提供不匹配的候选。因此，我们将所有候选存储在优先级队列 $Q$ 中，并始终选择期望匹配置信度最高的候选进行立体匹配
            - 在某些情况下，会为先前处理过的像素计算新的匹配。如果新的置信度高于先前的置信度，则新的匹配信息将覆盖旧的匹配信息。此外，如果像素的4个相邻像素尚未被处理并确定具有更高的置信度，则该像素的每个相邻像素被插入具有相同匹配信息的队列中。注意，当重新访问像素时，活动视图 $\mathbf{A}$ 的集合被重置，并允许使用局部视图选择标准从整个邻域集合 $\mathbf{N}$ 中绘制
            - 初始化优先级队列(Initializing the Priority Queue)
                - 在 $R$ 中可见的SFM特征提供了对场景几何结构的稳健但稀疏的估计，因此非常适合初始化 $Q$ 。我们使用在 $\mathbf{N}$ 中的所有相邻视图中可见的附加特征点来扩展该集合，将它们投影到R中以确定它们的像素位置。注意，这个附加集合可以包括在 $R$ 中实际上不可见的点；这些错误的初始化很可能会被重写
                - 然后，对于每个特征点，我们运行立体匹配程序，用特征的深度和正面平行法线初始化，以计算深度、法线和置信度。结果包括 $Q$ 的初始含量
        
        2. 作为优化的立体匹配(Stereo Matching as Optimization)
            - 我们将以参考视图 $R$ 中的像素为中心的n×n像素窗口解释为场景中一个小平面斑块的投影。然后，我们在匹配阶段的目标是优化该面片的深度和方向，以使其投影到相邻视图中的光度一致性最大化。其中一些视图可能不匹配，例如，由于遮挡或其他问题。这样的视图被拒绝为该修补程序无效，并被本地视图选择步骤提供的其他相邻视图替换
            ![Parametrization for stereo matching](../pictures/Parametrization%20for%20stereo%20matching.png)

            - 场景几何模型(Scene Geometry Model)
                - 我们假设以参考视图中的像素位置 $(s, t)$ 为中心的n×n像素窗口中可见的场景几何体由深度为 $h(s, t)$ 的平面定向窗口很好地建模。投影到中心像素的点的3D位置为 $$\begin{equation} \mathbf{x}_ {R}(s, t) = \mathbf{o}_ {R} + h(s, t) \cdot \vec{r}_ {R}(s, t) \end{equation}$$ 其中 $\mathbf{o}_ {R}$ 是视图 $R$ 的投影中心， $\vec{r}_ {R}(s, t)$ 是通过像素的归一化光线方向。我们使用每像素距离偏移 $h_ {s}(s, t)$ 和 $h_ {t}(s, t)$ 对窗口方向进行编码，分别对应于 $s$ 和 $t$ 方向上的每像素深度变化率。投影到匹配窗口内像素的点的3D位置为 $$\begin{equation} \mathbf{x}_ {R}(s+i,t+j) = \mathbf{o}_ {R} + [h(s, t) + i h_ {s}(s, t) + j h_ {t}(s, t)] \cdot \vec{r}_ {R}(s + i, t + j) \end{equation}$$ 其中， $i,j = - \frac{n-1}{2} \dots \frac{n-1}{2}$ 注意，这仅近似于平面窗口，但我们假设对于小 $n$ ，即当 $\vec{r}_ {R}(s + i, t + j) \thickapprox \vec{r}_ {R}(s, t)$ 。我们现在可以使用该视图的投影 $\mathbf{P}_ {k}(x_ {R}(s+i，t+j))$ 以亚像素精度确定相邻视图k中的对应位置。该公式用所有视图之间一致的表面方向的显式表示代替了常用的每个视图窗口形状参数，从而消除了多余的自由度
            - 光度模型(Photometric Model)
                - 虽然原则上我们可以对大量的反射效应进行建模，以提高在不同条件下拍摄的图像的匹配能力，但这是以增加更多参数为代价的。这样做不仅增加了计算工作量，而且降低了优化的稳定性。相反，我们使用了一个简单的反射率效应模型——投影到第 $k$ 个相邻视图中的每个面片的颜色比例因子 $c_ {k}$ 。给定视图（但不同于视图）和平面中的面片区域上的恒定照明，这完美地模拟了朗伯反射率。例如，当面片内的照明发生变化（例如，在阴影边界或焦散处）或面片包含镜面反射高光时，模型会失败。当视图之间的局部对比度发生变化时，它也会失败，例如，在不同方向照明下观察的凹凸不平的表面，或在某些视图中潮湿的表面，而在其他视图中则不然
                - 在实践中，当与视图选择结合使用时，该模型提供了足够的不变性，以在广泛的场景中产生良好的结果。此外，与该模型可靠匹配的视图范围与使用SIFT检测器匹配良好的图像具有良好的相关性
            - 带离群抑制的MPGC匹配(MPGC Matching with Outlier Rejection )
                - 给定上一节中的模型，我们现在可以将 $R$ 中的斑块内的像素强度与第 $k$ 个相邻视图中的强度联系起来： $$\begin{equation} I_ {R}(s+i, t+j) = c_ {k}(s,t) \cdot I_ {k}(\mathbf{P} _{k}(\mathbf{x}_ {R}(s+i,t+j))) \end{equation}$$ 其中， $i,j = - \frac{n-1}{2} \dots \frac{n-1}{2}, k=1 \dots m$ 在 $m=|\mathbf{A}|$ 是正在考虑的相邻视图的数量。省略像素坐标 $(s, t)$ 并代入等式7，我们得到 $$\begin{equation} I_ {R}(i, j) = c_ {k} \cdot I_ {k}(\mathbf{P} _{k}(\mathbf{o}_ {R} + \vec{r}_ {R}(i,j) \cdot (h+i h_ {s}+ j h_ {t}))) \end{equation}$$
                - 在3通道彩色图像的情况下，等式9表示三个等式，每个彩色通道一个。因此，考虑到窗口中的所有像素和所有相邻视图，我们有 $3 n^{2} m$ 个方程来求解 $3+3m$ 个未知数： $h$、 $h_ {s}$ 、 $h_ {t}$ 和每个视图的色标 $c_ {k}$。（在我们的所有实验中，我们设置n=5，m=4。）为了解决这个过度确定的非线性系统，我们遵循标准MPGC方法并线性化方程9： $$\begin{equation} I_ {R}(i, j) = c_ {k} \cdot I_ {k}(\mathbf{P} _{k}(\mathbf{o}_ {R} + \vec{r}_ {R}(i,j) \cdot (h+i h_ {s}+ j h_ {t}))) + \frac{\partial I_ {k}(i,j)}{\partial h} \cdot (d h + i \cdots d h_ {s} + j \cdot d h_ {t}) \end{equation}$$ 给定 $h$、 $h_ {s}$ 和 $h_ {t}$ 的初始值（然后我们保持不变），我们可以使用线性最小二乘法求解 $d h$、 $d h_ {s}$ 、 $d h_ {t}$ 和 $c_ {k}$ 。然后，我们通过分别添加 $d h$、 $d h_ {s}$ 和 $d h_ {t}$ 来更新 $h$、 $h_ {s}$ 和 $h_ {t}$ ，并进行迭代
                - 在这种优化中，我们本质上是在求解使参考窗口中的像素和相邻视图中的像素之间的平方差之和（SSD）最小的参数。我们本可以针对NCC的总和进行优化。然而，这些指标的行为有些不同。考虑场景平面部分的强度线性梯度的情况。在去除平均值和归一化后，NCC将允许移位窗口同样良好地匹配，从而导致不必要的深度模糊。现在考虑具有恒定反照率的无阴影平面区域的情况。在估计比例因子后，SSD优化将以接近零的误差收敛到最小值，基本上适合于噪声。相比之下，在去除平均值之后，NCC本质上是在测量两个视图之间的噪声相关性，这将是低的。在这种情况下，NCC很好地衡量了我们对解决方案的信心。如下所述，我们选择使用SSD进行参数估计，同时使用NCC测量置信度和收敛性
                - 尽管上述迭代优化方法趋向于快速收敛（即，在给定良好初始值的几次迭代内），但匹配问题将导致缓慢收敛、振荡或收敛到错误答案。因此，我们在优化中加入了特定的机制，以防止这些影响
                - 我们首先执行5次迭代以使系统稳定下来。在每次后续迭代之后，我们计算参考视图中的面片与每个相邻视图之间的NCC分数。然后，我们拒绝NCC评分低于接受阈值（通常 $\kappa =0.4$ ）的所有视图。如果没有视图被拒绝，并且与上一次迭代相比，所有NCC分数的变化不超过 $\epsilon=0.001$ ，我们假设迭代已经收敛。否则，我们将丢失的视图添加到活动集并继续迭代。如果我们在20次迭代后没有达到收敛，或者活动集包含的视图少于所需数量，则迭代失败
                - 在实践中，我们以两种方式修改上述过程，以显著改善其行为。首先，我们仅每第五次迭代或相邻视图的活动集发生变化时更新法线和色阶因子。这提高了性能并降低了振荡的可能性。第二，在第14次迭代之后（即，就在更新色阶因子和法线之前），我们拒绝所有NCC分数变化超过 $\epsilon$ 的视图，以停止可能的振荡
                - 如果优化收敛，并且法线和观察射线 $\vec{r}_ {R}(s, t)$ 之间的点积大于0.1，我们将置信度得分 $C$ 计算为参考视图中的斑块和所有活动相邻视图之间的平均NCC得分，从 $[\kappa \dots 1]$ 归一化为 $[0 \dots 1]$。我们使用这个分数来确定如何更新深度、法线和置信度图和 $Q$
# 四、实验结果
![Test LVS ON](../pictures/Test%20LVS%20ON.png)

## 1、比之前模型的优势

## 2、有优势的原因

## 3、改进空间

# 五、结论

## 1、模型是否解决了目标问题

## 2、模型是否遗留了问题

## 3、模型是否引入了新的问题

# 六、代码

# 读者角度（挖掘文章中没有提到的）：
1. 总结文章发现问题的思路
2. 总结文章改进的思想
3. 总结文章还存在或者可以改进的问题
4. 提出对模型参数和细节的一些思考和讨论